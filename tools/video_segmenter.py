#!/usr/bin/env python3
"""
SSIM ê¸°ë°˜ ìŠ¤ë§ˆíŠ¸ ë¹„ë””ì˜¤ ì„¸ê·¸ë©˜í…Œì´ì…˜
ë¹„ë””ì˜¤ë¥¼ ë™ì  ë°°ê²½ êµ¬ê°„ìœ¼ë¡œ ë¶„í• í•˜ì—¬ YOLO ê³¼ì í•© ë°©ì§€ ë° ë¼ë²¨ë§ íš¨ìœ¨ ê·¹ëŒ€í™”
UIëŠ” ê³ ì •ë˜ê³  ë°°ê²½ë§Œ ë³€í•˜ëŠ” êµ¬ê°„ ì„ íƒ

ì‚¬ìš©ë²•:
    python tools/video_segmenter.py --input datasets/raw/gameplay.mp4 \
                                     --output datasets/clips/ \
                                     --dynamic-low 0.4 \
                                     --dynamic-high 0.8 \
                                     --min-duration 5
"""

import argparse
import cv2
import numpy as np
from pathlib import Path
from typing import List, Tuple, Optional
from dataclasses import dataclass
import json
from datetime import datetime
from skimage.metrics import structural_similarity as ssim
import subprocess
import shutil
import sys


def refresh_system_path():
    """
    ì‹œìŠ¤í…œ PATH í™˜ê²½ë³€ìˆ˜ë¥¼ ë ˆì§€ìŠ¤íŠ¸ë¦¬ì—ì„œ ìƒˆë¡œê³ ì¹¨ (Windows ì „ìš©)
    winget ì„¤ì¹˜ í›„ í˜„ì¬ í”„ë¡œì„¸ìŠ¤ì—ì„œ PATHë¥¼ ì¦‰ì‹œ ì‚¬ìš©í•˜ê¸° ìœ„í•¨
    """
    if sys.platform != 'win32':
        return

    try:
        import winreg
        import os

        # ì‹œìŠ¤í…œ PATH ì½ê¸°
        with winreg.OpenKey(winreg.HKEY_LOCAL_MACHINE,
                           r'SYSTEM\CurrentControlSet\Control\Session Manager\Environment',
                           0, winreg.KEY_READ) as key:
            system_path, _ = winreg.QueryValueEx(key, 'Path')

        # ì‚¬ìš©ì PATH ì½ê¸°
        with winreg.OpenKey(winreg.HKEY_CURRENT_USER,
                           r'Environment',
                           0, winreg.KEY_READ) as key:
            try:
                user_path, _ = winreg.QueryValueEx(key, 'Path')
            except FileNotFoundError:
                user_path = ''

        # í˜„ì¬ í”„ë¡œì„¸ìŠ¤ì˜ PATH ì—…ë°ì´íŠ¸
        combined_path = f"{user_path};{system_path}" if user_path else system_path
        os.environ['PATH'] = combined_path

    except Exception as e:
        # PATH ìƒˆë¡œê³ ì¹¨ ì‹¤íŒ¨ëŠ” ì¹˜ëª…ì ì´ì§€ ì•Šìœ¼ë¯€ë¡œ ë¬´ì‹œ
        pass


def check_and_install_ffmpeg() -> bool:
    """
    ffmpeg ì„¤ì¹˜ ì—¬ë¶€ í™•ì¸ ë° ìë™ ì„¤ì¹˜

    Returns:
        bool: ffmpegê°€ ì‚¬ìš© ê°€ëŠ¥í•˜ë©´ True, ì„¤ì¹˜ ì‹¤íŒ¨í•˜ë©´ False
    """
    # ffmpegê°€ ì´ë¯¸ PATHì— ìˆëŠ”ì§€ í™•ì¸
    if shutil.which('ffmpeg') is not None:
        return True

    print("âš ï¸ ffmpegë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    print("ğŸ”§ ffmpegë¥¼ ìë™ìœ¼ë¡œ ì„¤ì¹˜í•©ë‹ˆë‹¤ (winget ì‚¬ìš©)...")

    try:
        # wingetìœ¼ë¡œ ffmpeg ì„¤ì¹˜ ì‹œë„
        result = subprocess.run(
            ['winget', 'install', 'Gyan.FFmpeg', '--accept-source-agreements', '--accept-package-agreements'],
            capture_output=True,
            text=True,
            timeout=300  # 5ë¶„ íƒ€ì„ì•„ì›ƒ
        )

        if result.returncode == 0:
            print("âœ… ffmpeg ì„¤ì¹˜ ì™„ë£Œ!")

            # PATH ìƒˆë¡œê³ ì¹¨ ì‹œë„
            print("ğŸ”„ PATH í™˜ê²½ë³€ìˆ˜ ìƒˆë¡œê³ ì¹¨ ì¤‘...")
            refresh_system_path()

            # ì„¤ì¹˜ í›„ ë‹¤ì‹œ í™•ì¸
            if shutil.which('ffmpeg') is not None:
                print("âœ… ffmpegë¥¼ ë°”ë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤!")
                return True
            else:
                print("   âš ï¸ ì„¤ì¹˜ëŠ” ì™„ë£Œë˜ì—ˆìœ¼ë‚˜ PATHì—ì„œ ffmpegë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                print("   â„¹ï¸ ë‹¤ìŒ ì¤‘ í•˜ë‚˜ë¥¼ ì‹œë„í•´ì£¼ì„¸ìš”:")
                print("      1. í„°ë¯¸ë„ì„ ì¬ì‹œì‘í•œ í›„ ë‹¤ì‹œ ì‹¤í–‰")
                print("      2. ì‹œìŠ¤í…œì„ ì¬ë¶€íŒ…")
                return False
        else:
            print(f"âŒ ffmpeg ì„¤ì¹˜ ì‹¤íŒ¨")
            if result.stderr:
                print(f"   ì˜¤ë¥˜ ë©”ì‹œì§€: {result.stderr[:200]}")
            print("   â„¹ï¸ ìˆ˜ë™ ì„¤ì¹˜ ë°©ë²•:")
            print("      1. í„°ë¯¸ë„ì—ì„œ 'winget install Gyan.FFmpeg' ì‹¤í–‰")
            print("      2. ë˜ëŠ” https://www.gyan.dev/ffmpeg/builds/ ì—ì„œ ë‹¤ìš´ë¡œë“œ")
            return False

    except FileNotFoundError:
        print("âŒ wingetì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        print("   â„¹ï¸ Windows 10 1809 ì´ìƒ ë˜ëŠ” Windows 11ì´ í•„ìš”í•©ë‹ˆë‹¤.")
        print("   â„¹ï¸ ìˆ˜ë™ ì„¤ì¹˜: https://www.gyan.dev/ffmpeg/builds/")
        return False
    except subprocess.TimeoutExpired:
        print("âŒ ffmpeg ì„¤ì¹˜ ì‹œê°„ ì´ˆê³¼ (5ë¶„)")
        print("   â„¹ï¸ ë„¤íŠ¸ì›Œí¬ ìƒíƒœë¥¼ í™•ì¸í•˜ê³  ìˆ˜ë™ìœ¼ë¡œ ì„¤ì¹˜í•´ì£¼ì„¸ìš”.")
        return False
    except Exception as e:
        print(f"âŒ ffmpeg ì„¤ì¹˜ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}")
        return False


class PyAVVideoReader:
    """
    PyAVë¥¼ ì‚¬ìš©í•œ ë¹„ë””ì˜¤ ë¦¬ë” (OpenCVê°€ ì§€ì›í•˜ì§€ ì•ŠëŠ” ì½”ë± ì²˜ë¦¬)
    AV1, H.265, VP9 ë“± ëª¨ë“  FFmpeg ì§€ì› ì½”ë±ì„ ë¬´ì†ì‹¤ë¡œ ì½ì„ ìˆ˜ ìˆìŒ
    """

    def __init__(self, video_path: Path):
        """
        Args:
            video_path: ë¹„ë””ì˜¤ íŒŒì¼ ê²½ë¡œ
        """
        self.video_path = video_path
        self.container = None
        self.video_stream = None
        self.fps = None
        self.total_frames = None
        self.width = None
        self.height = None
        self._frame_generator = None

    def open(self) -> bool:
        """
        ë¹„ë””ì˜¤ íŒŒì¼ ì—´ê¸°

        Returns:
            bool: ì„±ê³µ ì—¬ë¶€
        """
        try:
            import av

            self.container = av.open(str(self.video_path))
            self.video_stream = self.container.streams.video[0]

            # ë¹„ë””ì˜¤ ì •ë³´ ì¶”ì¶œ
            self.fps = float(self.video_stream.average_rate)
            self.total_frames = self.video_stream.frames
            self.width = self.video_stream.width
            self.height = self.video_stream.height

            # total_framesê°€ 0ì´ë©´ durationìœ¼ë¡œ ì¶”ì •
            if self.total_frames == 0 and self.container.duration:
                self.total_frames = int(self.container.duration * self.fps / av.time_base)

            # í”„ë ˆì„ ì œë„ˆë ˆì´í„° ì´ˆê¸°í™”
            self._frame_generator = self.container.decode(video=0)

            print(f"âœ… PyAVë¡œ ë¹„ë””ì˜¤ ì—´ê¸° ì„±ê³µ")
            print(f"   ì½”ë±: {self.video_stream.codec_context.name}")

            return True

        except ImportError:
            print("âš ï¸ PyAVê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            print("   ì„¤ì¹˜ ë°©ë²•: pip install av")
            return False
        except Exception as e:
            print(f"âš ï¸ PyAVë¡œ ë¹„ë””ì˜¤ ì—´ê¸° ì‹¤íŒ¨: {e}")
            return False

    def read(self):
        """
        ë‹¤ìŒ í”„ë ˆì„ ì½ê¸° (OpenCVì˜ cap.read()ì™€ ë™ì¼í•œ ì¸í„°í˜ì´ìŠ¤)

        Returns:
            tuple: (success, frame_bgr) - OpenCV í˜•ì‹ì˜ BGR numpy array
        """
        try:
            frame = next(self._frame_generator)
            # BGR í¬ë§·ìœ¼ë¡œ ë³€í™˜ (OpenCV í˜¸í™˜)
            img = frame.to_ndarray(format='bgr24')
            return True, img
        except StopIteration:
            return False, None
        except Exception as e:
            return False, None

    def grab(self):
        """
        í”„ë ˆì„ì„ ê±´ë„ˆë›°ê¸° (OpenCVì˜ cap.grab()ì™€ ë™ì¼í•œ ì¸í„°í˜ì´ìŠ¤)
        PyAVëŠ” grabì„ ì§ì ‘ ì§€ì›í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ readí•˜ê³  ë²„ë¦¼

        Returns:
            bool: ì„±ê³µ ì—¬ë¶€
        """
        try:
            frame = next(self._frame_generator)
            return True
        except StopIteration:
            return False
        except Exception as e:
            return False

    def release(self):
        """ë¦¬ì†ŒìŠ¤ í•´ì œ"""
        if self.container:
            self.container.close()
            self.container = None

    def isOpened(self) -> bool:
        """ë¹„ë””ì˜¤ê°€ ì—´ë ¤ìˆëŠ”ì§€ í™•ì¸"""
        return self.container is not None


@dataclass
class VideoSegment:
    """ë¹„ë””ì˜¤ ì„¸ê·¸ë¨¼íŠ¸ ì •ë³´"""
    start_frame: int
    end_frame: int
    start_time: float
    end_time: float
    duration: float
    avg_ssim: float  # êµ¬ê°„ ë‚´ í‰ê·  SSIM (ì•ˆì •ì„± ì§€í‘œ)


@dataclass
class SegmentConfig:
    """ì„¸ê·¸ë©˜í…Œì´ì…˜ ì„¤ì •"""
    # ì¥ë©´ ì „í™˜ ê°ì§€ (ë„ˆë¬´ ë‚®ì€ SSIM)
    scene_change_threshold: float = 0.3  # SSIMì´ ì´ë³´ë‹¤ ë‚®ìœ¼ë©´ ì¥ë©´ ì „í™˜ (ì œì™¸)

    # ì •ì  êµ¬ê°„ ê°ì§€ (ë„ˆë¬´ ë†’ì€ SSIM = ì ìˆ˜ êµ¬ê°„)
    static_threshold: float = 0.95       # SSIMì´ ì´ë³´ë‹¤ ë†’ìœ¼ë©´ ë„ˆë¬´ ì •ì  (ì œì™¸)
    min_dynamic_frames: int = 30         # ìµœì†Œ ë™ì  í”„ë ˆì„ ìˆ˜ (1ì´ˆ@30fps)

    # ì„¸ê·¸ë¨¼íŠ¸ ì œì•½
    min_duration: float = 5.0            # ìµœì†Œ ì„¸ê·¸ë¨¼íŠ¸ ê¸¸ì´ (ì´ˆ)
    max_duration: float = 60.0           # ìµœëŒ€ ì„¸ê·¸ë¨¼íŠ¸ ê¸¸ì´ (ì´ˆ)
    max_segments: Optional[int] = None   # ìµœëŒ€ ì„¸ê·¸ë¨¼íŠ¸ ìˆ˜

    # ì„±ëŠ¥ ìµœì í™”
    ssim_scale: float = 1.0              # SSIM ê³„ì‚° ì‹œ í•´ìƒë„ ìŠ¤ì¼€ì¼ (0.25 = 4ë°° ë¹ ë¦„, ì¶œë ¥ì€ ì›ë³¸ ìœ ì§€)
    frame_skip: int = 1                  # í”„ë ˆì„ ìŠ¤í‚µ (1=ëª¨ë“  í”„ë ˆì„, 3=3í”„ë ˆì„ë§ˆë‹¤)
    use_gpu: bool = False                # GPU ê°€ì† ì‚¬ìš© (CUDA ì‚¬ìš© ê°€ëŠ¥ ì‹œ)

    # ì‹¤í—˜ ê¸°ëŠ¥
    save_discarded: bool = False         # ì±„íƒë˜ì§€ ì•Šì€ êµ¬ê°„ë„ ë³„ë„ ì €ì¥

    # ì¶œë ¥ ì„¤ì •
    output_codec: str = "mp4v"           # ì¶œë ¥ ì½”ë±
    output_fps: Optional[int] = None     # ì¶œë ¥ FPS (Noneì´ë©´ ì›ë³¸)


class VideoSegmenter:
    """SSIM ê¸°ë°˜ ë¹„ë””ì˜¤ ì„¸ê·¸ë©˜í…Œì´ì…˜"""

    def __init__(self, config: SegmentConfig = None):
        self.config = config or SegmentConfig()
        self.stats = {
            'total_frames': 0,
            'scene_changes': 0,
            'dynamic_segments': 0,
            'discarded_short': 0,
            'discarded_static': 0,
            'ssim_gpu_count': 0,      # GPUë¡œ ê³„ì‚°í•œ SSIM íšŸìˆ˜
            'ssim_cpu_count': 0,      # CPUë¡œ ê³„ì‚°í•œ SSIM íšŸìˆ˜
            'ssim_gpu_time': 0.0,     # GPU SSIM ì´ ì‹œê°„ (ì´ˆ)
            'ssim_cpu_time': 0.0,     # CPU SSIM ì´ ì‹œê°„ (ì´ˆ)
        }

        # GPU ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
        self.gpu_available = False
        self.device = None
        if self.config.use_gpu:
            self.gpu_available = self._check_gpu_available()

    def _check_gpu_available(self) -> bool:
        """
        GPU ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸ (CUDA/PyTorch)

        Returns:
            bool: GPU ì‚¬ìš© ê°€ëŠ¥í•˜ë©´ True
        """
        try:
            # 1. PyTorch ì„¤ì¹˜ ê²½ë¡œë¥¼ sys.pathì— ì¶”ê°€
            import sys
            from pathlib import Path
            import os

            # src/utils ê²½ë¡œ ì¶”ê°€ (PyTorchInstaller importìš©)
            if getattr(sys, 'frozen', False):
                # PyInstaller íŒ¨í‚¤ì§• í™˜ê²½
                utils_dir = Path(sys.executable).parent / "_internal" / "src"
            else:
                # ê°œë°œ í™˜ê²½
                script_dir = Path(__file__).parent.parent
                utils_dir = script_dir / "src"

            if utils_dir.exists() and str(utils_dir) not in sys.path:
                sys.path.insert(0, str(utils_dir))

            # 2. PyTorch ì„¤ì¹˜ í™•ì¸
            try:
                from utils.pytorch_installer import PyTorchInstaller
                installer = PyTorchInstaller.get_instance()

                if not installer.is_pytorch_installed():
                    print("âš ï¸ PyTorchê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. CPU ëª¨ë“œë¡œ ì‹¤í–‰í•©ë‹ˆë‹¤.")
                    print("   GPU ê°€ì†ì„ ì‚¬ìš©í•˜ë ¤ë©´ GUIì—ì„œ 'GPU ê°€ì†' ì²´í¬ë°•ìŠ¤ë¥¼ í™œì„±í™”í•˜ì„¸ìš”.")
                    return False

                # sys.pathì— PyTorch ê²½ë¡œ ì¶”ê°€
                installer.add_to_path()

            except ImportError:
                # PyTorchInstallerë¥¼ ì°¾ì„ ìˆ˜ ì—†ëŠ” ê²½ìš° (ì´ì „ ë²„ì „ í˜¸í™˜ì„±)
                print("âš ï¸ PyTorchInstallerë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì‹œìŠ¤í…œ PyTorchë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")

            # 3. PyTorch import ì‹œë„
            import torch

            if torch.cuda.is_available():
                self.device = torch.device('cuda')
                gpu_name = torch.cuda.get_device_name(0)
                print(f"âœ… GPU ê°ì§€ë¨: {gpu_name}")

                # 4. ì‹¤ì œ GPU í…ì„œ ìƒì„± ë° ì—°ì‚° í…ŒìŠ¤íŠ¸
                print("ğŸ” GPU ì´ˆê¸°í™” í…ŒìŠ¤íŠ¸ ì¤‘...")
                try:
                    # ì‘ì€ í–‰ë ¬ ê³±ì…ˆìœ¼ë¡œ GPU ì‘ë™ í™•ì¸
                    test_tensor = torch.randn(100, 100, device=self.device)
                    result = test_tensor @ test_tensor.T
                    torch.cuda.synchronize()  # GPU ì‘ì—… ì™„ë£Œ ëŒ€ê¸°

                    # ë©”ëª¨ë¦¬ ì •ë³´ í™•ì¸
                    memory_allocated = torch.cuda.memory_allocated(0) / 1024 / 1024  # MB
                    memory_reserved = torch.cuda.memory_reserved(0) / 1024 / 1024    # MB

                    print(f"âœ… GPU ê°€ì† í™œì„±í™” ì„±ê³µ!")
                    print(f"   - GPU ë©”ëª¨ë¦¬ í• ë‹¹: {memory_allocated:.1f} MB")
                    print(f"   - GPU ë©”ëª¨ë¦¬ ì˜ˆì•½: {memory_reserved:.1f} MB")
                    return True

                except RuntimeError as e:
                    print(f"âŒ GPU í…ì„œ ìƒì„± ì‹¤íŒ¨: {e}")
                    print("   CPU ëª¨ë“œë¡œ ì‹¤í–‰í•©ë‹ˆë‹¤.")
                    return False
                except Exception as e:
                    print(f"âŒ GPU ì´ˆê¸°í™” í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
                    print("   CPU ëª¨ë“œë¡œ ì‹¤í–‰í•©ë‹ˆë‹¤.")
                    return False
            else:
                print("âš ï¸ CUDAë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. CPU ëª¨ë“œë¡œ ì‹¤í–‰í•©ë‹ˆë‹¤.")
                return False

        except ImportError:
            print("âš ï¸ PyTorchê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. CPU ëª¨ë“œë¡œ ì‹¤í–‰í•©ë‹ˆë‹¤.")
            print("   GPU ê°€ì†ì„ ì‚¬ìš©í•˜ë ¤ë©´ GUIì—ì„œ 'GPU ê°€ì†' ì²´í¬ë°•ìŠ¤ë¥¼ í™œì„±í™”í•˜ì„¸ìš”.")
            return False
        except (OSError, RuntimeError) as e:
            # DLL ë¡œë”© ì‹¤íŒ¨ ë˜ëŠ” CUDA ì´ˆê¸°í™” ì˜¤ë¥˜
            print(f"âš ï¸ PyTorch ë¡œë”© ì‹¤íŒ¨: {e}")
            print("   CPU ëª¨ë“œë¡œ ì‹¤í–‰í•©ë‹ˆë‹¤.")
            print("   í•´ê²° ë°©ë²•:")
            print("   1. GUIì—ì„œ 'GPU ê°€ì†' ì²´í¬ë°•ìŠ¤ë¥¼ ë‹¤ì‹œ í™œì„±í™”í•˜ì„¸ìš”.")
            print("   2. PyTorch ì¬ì„¤ì¹˜: ì„¤ì • ë©”ë‰´ì—ì„œ 'PyTorch ì¬ì„¤ì¹˜' í´ë¦­")
            return False
        except Exception as e:
            # ê¸°íƒ€ ëª¨ë“  ì˜ˆì™¸
            print(f"âš ï¸ GPU ì´ˆê¸°í™” ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}")
            print("   CPU ëª¨ë“œë¡œ ì‹¤í–‰í•©ë‹ˆë‹¤.")
            return False

    def calculate_ssim(self, img1: np.ndarray, img2: np.ndarray) -> float:
        """
        ë‘ ì´ë¯¸ì§€ ê°„ SSIM ê³„ì‚° (CPU ë˜ëŠ” GPU)

        ì„±ëŠ¥ ìµœì í™”: config.ssim_scale < 1.0ì´ë©´ í•´ìƒë„ ì¶•ì†Œ í›„ ê³„ì‚°
        (segment êµ¬ê°„ ê²°ì •ì—ë§Œ ì‚¬ìš©, ì¶œë ¥ì€ ì›ë³¸ í•´ìƒë„ ìœ ì§€)
        """
        import time

        # í•´ìƒë„ ì¶•ì†Œ (ì„¤ì •ëœ ê²½ìš°)
        if self.config.ssim_scale < 1.0:
            h, w = img1.shape[:2]
            new_h = int(h * self.config.ssim_scale)
            new_w = int(w * self.config.ssim_scale)
            img1 = cv2.resize(img1, (new_w, new_h), interpolation=cv2.INTER_AREA)
            img2 = cv2.resize(img2, (new_w, new_h), interpolation=cv2.INTER_AREA)

        # GPU ê°€ì† ì‚¬ìš© (PyTorch ì‚¬ìš© ê°€ëŠ¥ ì‹œ)
        if self.gpu_available:
            try:
                start_time = time.perf_counter()
                score = self._calculate_ssim_gpu(img1, img2)
                elapsed = time.perf_counter() - start_time

                self.stats['ssim_gpu_count'] += 1
                self.stats['ssim_gpu_time'] += elapsed
                return score
            except (OSError, RuntimeError, Exception) as e:
                # GPU ê³„ì‚° ì‹¤íŒ¨ ì‹œ CPUë¡œ ìë™ í´ë°±
                print(f"âš ï¸ GPU SSIM ê³„ì‚° ì‹¤íŒ¨, CPUë¡œ ì „í™˜: {e}")
                self.gpu_available = False  # ì´í›„ ëª¨ë“  ê³„ì‚°ì€ CPU ì‚¬ìš©

        # CPU ë²„ì „ (ê¸°ì¡´ ì½”ë“œ)
        start_time = time.perf_counter()
        gray1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)
        gray2 = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)
        score, _ = ssim(gray1, gray2, full=True)
        elapsed = time.perf_counter() - start_time

        self.stats['ssim_cpu_count'] += 1
        self.stats['ssim_cpu_time'] += elapsed
        return score

    def _calculate_ssim_gpu_batch(self, frame_pairs: list) -> list:
        """
        GPUë¥¼ ì‚¬ìš©í•œ ë°°ì¹˜ SSIM ê³„ì‚° (PyTorch) - ì„±ëŠ¥ ìµœì í™”

        Args:
            frame_pairs: [(img1, img2), ...] í”„ë ˆì„ ìŒ ë¦¬ìŠ¤íŠ¸

        Returns:
            SSIM ì ìˆ˜ ë¦¬ìŠ¤íŠ¸
        """
        try:
            import torch
            import torch.nn.functional as F

            if not frame_pairs:
                return []

            batch_size = len(frame_pairs)

            # BGR to Grayscale (CPUì—ì„œ ë°°ì¹˜ ì²˜ë¦¬)
            gray1_list = []
            gray2_list = []

            for img1, img2 in frame_pairs:
                gray1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)
                gray2 = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)
                gray1_list.append(gray1)
                gray2_list.append(gray2)

            # NumPy to Torch Tensor (ë°°ì¹˜)
            gray1_batch = np.stack(gray1_list)
            gray2_batch = np.stack(gray2_list)

            t1 = torch.from_numpy(gray1_batch).float().unsqueeze(1).to(self.device) / 255.0
            t2 = torch.from_numpy(gray2_batch).float().unsqueeze(1).to(self.device) / 255.0

            # SSIM ê³„ì‚° (ë°°ì¹˜)
            C1 = 0.01 ** 2
            C2 = 0.03 ** 2

            mu1 = F.avg_pool2d(t1, 11, 1, 5)
            mu2 = F.avg_pool2d(t2, 11, 1, 5)

            mu1_sq = mu1 ** 2
            mu2_sq = mu2 ** 2
            mu1_mu2 = mu1 * mu2

            sigma1_sq = F.avg_pool2d(t1 ** 2, 11, 1, 5) - mu1_sq
            sigma2_sq = F.avg_pool2d(t2 ** 2, 11, 1, 5) - mu2_sq
            sigma12 = F.avg_pool2d(t1 * t2, 11, 1, 5) - mu1_mu2

            ssim_map = ((2 * mu1_mu2 + C1) * (2 * sigma12 + C2)) / \
                       ((mu1_sq + mu2_sq + C1) * (sigma1_sq + sigma2_sq + C2))

            # ë°°ì¹˜ë³„ í‰ê·  SSIM ì ìˆ˜
            scores = ssim_map.mean(dim=(1, 2, 3)).cpu().tolist()
            return scores

        except Exception as e:
            # GPU ì˜¤ë¥˜ ì‹œ CPUë¡œ í´ë°± (ë‹¨ì¼ í”„ë ˆì„ ì²˜ë¦¬)
            print(f"âš ï¸ GPU ë°°ì¹˜ SSIM ê³„ì‚° ì‹¤íŒ¨, CPUë¡œ í´ë°±: {e}")
            scores = []
            for img1, img2 in frame_pairs:
                gray1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)
                gray2 = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)
                score, _ = ssim(gray1, gray2, full=True)
                scores.append(score)
            return scores

    def _calculate_ssim_gpu(self, img1: np.ndarray, img2: np.ndarray) -> float:
        """
        GPUë¥¼ ì‚¬ìš©í•œ SSIM ê³„ì‚° (PyTorch)

        Args:
            img1: ì²« ë²ˆì§¸ ì´ë¯¸ì§€ (BGR)
            img2: ë‘ ë²ˆì§¸ ì´ë¯¸ì§€ (BGR)

        Returns:
            SSIM ì ìˆ˜
        """
        try:
            import torch
            import torch.nn.functional as F

            # BGR to Grayscale
            gray1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)
            gray2 = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)

            # NumPy to Torch Tensor
            t1 = torch.from_numpy(gray1).float().unsqueeze(0).unsqueeze(0).to(self.device) / 255.0
            t2 = torch.from_numpy(gray2).float().unsqueeze(0).unsqueeze(0).to(self.device) / 255.0

            # SSIM ê³„ì‚° (ê°„ë‹¨í•œ ë²„ì „)
            C1 = 0.01 ** 2
            C2 = 0.03 ** 2

            mu1 = F.avg_pool2d(t1, 11, 1, 5)
            mu2 = F.avg_pool2d(t2, 11, 1, 5)

            mu1_sq = mu1 ** 2
            mu2_sq = mu2 ** 2
            mu1_mu2 = mu1 * mu2

            sigma1_sq = F.avg_pool2d(t1 ** 2, 11, 1, 5) - mu1_sq
            sigma2_sq = F.avg_pool2d(t2 ** 2, 11, 1, 5) - mu2_sq
            sigma12 = F.avg_pool2d(t1 * t2, 11, 1, 5) - mu1_mu2

            ssim_map = ((2 * mu1_mu2 + C1) * (2 * sigma12 + C2)) / \
                       ((mu1_sq + mu2_sq + C1) * (sigma1_sq + sigma2_sq + C2))

            score = ssim_map.mean().item()
            return score

        except Exception as e:
            # GPU ì˜¤ë¥˜ ì‹œ CPUë¡œ í´ë°±
            print(f"âš ï¸ GPU SSIM ê³„ì‚° ì‹¤íŒ¨, CPUë¡œ í´ë°±: {e}")
            gray1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)
            gray2 = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)
            score, _ = ssim(gray1, gray2, full=True)
            return score

    def detect_segments(
        self,
        video_path: Path,
        progress_callback=None
    ) -> List[VideoSegment]:
        """
        ë¹„ë””ì˜¤ì—ì„œ ë™ì ì¸ ì„¸ê·¸ë¨¼íŠ¸ íƒì§€ (ì •ì ì¸ 'ì ìˆ˜ êµ¬ê°„'ë§Œ ì œì™¸)

        Args:
            video_path: ì…ë ¥ ë¹„ë””ì˜¤ ê²½ë¡œ
            progress_callback: ì§„í–‰ ìƒí™© ì½œë°± í•¨ìˆ˜(current, total)

        Returns:
            VideoSegment ë¦¬ìŠ¤íŠ¸
        """
        return self._detect_segments_single(video_path, progress_callback)

    def _detect_segments_single(
        self,
        video_path: Path,
        progress_callback=None
    ) -> List[VideoSegment]:
        """
        ì‹±ê¸€ í”„ë¡œì„¸ìŠ¤ ì„¸ê·¸ë¨¼íŠ¸ íƒì§€

        Args:
            video_path: ì…ë ¥ ë¹„ë””ì˜¤ ê²½ë¡œ
            progress_callback: ì§„í–‰ ìƒí™© ì½œë°± í•¨ìˆ˜(current, total)

        Returns:
            VideoSegment ë¦¬ìŠ¤íŠ¸
        """
        # ë¹„ë””ì˜¤ ë¦¬ë” (OpenCV ë˜ëŠ” PyAV)
        cap = None
        using_pyav = False

        # 1ë‹¨ê³„: OpenCVë¡œ ì—´ê¸° ì‹œë„
        cap = cv2.VideoCapture(str(video_path))
        if not cap.isOpened():
            raise RuntimeError(f"ë¹„ë””ì˜¤ë¥¼ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {video_path}")

        fps = cap.get(cv2.CAP_PROP_FPS)
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        self.stats['total_frames'] = total_frames

        print(f"ğŸ“¹ ë¹„ë””ì˜¤ ë¶„ì„ ì¤‘...")
        print(f"   - FPS: {fps:.2f}")
        print(f"   - ì´ í”„ë ˆì„: {total_frames:,}ê°œ")
        print(f"   - ê¸¸ì´: {total_frames / fps / 60:.1f}ë¶„")
        if self.config.ssim_scale < 1.0:
            print(f"   - SSIM í•´ìƒë„ ìŠ¤ì¼€ì¼: {self.config.ssim_scale:.2f} (ì„±ëŠ¥ ìµœì í™” ì ìš©, ì¶œë ¥ì€ ì›ë³¸ ìœ ì§€)")
        if self.config.frame_skip > 1:
            print(f"   - í”„ë ˆì„ ìŠ¤í‚µ: {self.config.frame_skip} (ë¹ ë¥¸ ëª¨ë“œ, ~{self.config.frame_skip}ë°° ì†ë„ í–¥ìƒ)")

        segments = []
        current_segment_start = 0
        dynamic_frame_count = 0
        ssim_buffer = []

        # ì²« í”„ë ˆì„ ì½ê¸° ì‹œë„
        ret, prev_frame = cap.read()
        if not ret:
            # 2ë‹¨ê³„: OpenCV ì‹¤íŒ¨ ì‹œ PyAVë¡œ ì „í™˜
            print("âš ï¸ OpenCVë¡œ ì²« í”„ë ˆì„ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            print("   ë¹„ë””ì˜¤ ì½”ë±ì´ OpenCVì™€ í˜¸í™˜ë˜ì§€ ì•Šì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            print("ğŸ”„ PyAVë¡œ ì „í™˜ì„ ì‹œë„í•©ë‹ˆë‹¤...")
            cap.release()

            # PyAVë¡œ ì—´ê¸°
            cap = PyAVVideoReader(video_path)
            if not cap.open():
                raise RuntimeError(
                    "ì²« í”„ë ˆì„ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n"
                    "ë¹„ë””ì˜¤ íŒŒì¼ì´ ì†ìƒë˜ì—ˆê±°ë‚˜ PyAVê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\n"
                    "PyAV ì„¤ì¹˜: pip install av"
                )

            # PyAVì—ì„œ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
            fps = cap.fps
            total_frames = cap.total_frames
            self.stats['total_frames'] = total_frames
            using_pyav = True

            # ì²« í”„ë ˆì„ ë‹¤ì‹œ ì½ê¸°
            ret, prev_frame = cap.read()
            if not ret:
                cap.release()
                raise RuntimeError("PyAVë¡œë„ ì²« í”„ë ˆì„ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")

        frame_idx = 0

        # Progress update ì‹œê°„ ê¸°ë°˜ ì œì–´
        import time
        last_update_time = time.time()
        UPDATE_INTERVAL = 0.1  # 0.1ì´ˆ(100ms)ë§ˆë‹¤ ì—…ë°ì´íŠ¸

        # GPU ë°°ì¹˜ ì²˜ë¦¬ ì„¤ì •
        BATCH_SIZE = 32  # GPU ë©”ëª¨ë¦¬ì— ë”°ë¼ ì¡°ì • ê°€ëŠ¥
        frame_batch = []  # [(prev_frame, current_frame), ...]
        frame_indices = []  # ê° ë°°ì¹˜ í”„ë ˆì„ì˜ ì¸ë±ìŠ¤

        use_batch_processing = (self.device and self.device.type == 'cuda')

        if use_batch_processing:
            print(f"ğŸš€ GPU ë°°ì¹˜ ì²˜ë¦¬ ëª¨ë“œ (ë°°ì¹˜ í¬ê¸°: {BATCH_SIZE})")

        while True:
            # í”„ë ˆì„ ìŠ¤í‚µ ì ìš©
            for _ in range(self.config.frame_skip - 1):
                ret = cap.grab()  # í”„ë ˆì„ ì½ì§€ ì•Šê³  ê±´ë„ˆë›°ê¸°
                if not ret:
                    break
                frame_idx += 1

            ret, current_frame = cap.read()
            if not ret:
                break

            frame_idx += 1

            # ì‹œê°„ ê¸°ë°˜ ì§„í–‰ë¥  ì—…ë°ì´íŠ¸ (0.1ì´ˆë§ˆë‹¤)
            current_time = time.time()
            if progress_callback and (current_time - last_update_time >= UPDATE_INTERVAL):
                progress_callback(frame_idx, total_frames)
                last_update_time = current_time

            # ë°°ì¹˜ ì²˜ë¦¬ ëª¨ë“œ
            if use_batch_processing:
                # ë°°ì¹˜ì— í”„ë ˆì„ ì¶”ê°€
                frame_batch.append((prev_frame.copy(), current_frame.copy()))
                frame_indices.append(frame_idx)

                # ë°°ì¹˜ê°€ ê°€ë“ ì°¨ë©´ ì²˜ë¦¬
                if len(frame_batch) >= BATCH_SIZE:
                    try:
                        # GPU ë°°ì¹˜ SSIM ê³„ì‚°
                        ssim_scores = self._calculate_ssim_gpu_batch(frame_batch)

                        # ê²°ê³¼ ì²˜ë¦¬
                        for batch_idx, ssim_score in enumerate(ssim_scores):
                            ssim_buffer.append(ssim_score)

                            # ì¥ë©´ ì „í™˜ ê°ì§€ ì²˜ë¦¬ (ì•„ë˜ì—ì„œ í†µí•©)
                            batch_frame_idx = frame_indices[batch_idx]
                            if ssim_score < self.config.scene_change_threshold:
                                self.stats['scene_changes'] += 1

                                if dynamic_frame_count >= self.config.min_dynamic_frames:
                                    segment = self._create_segment(
                                        current_segment_start,
                                        batch_frame_idx - 1,
                                        fps,
                                        ssim_buffer[:-1]
                                    )

                                    if self._is_valid_segment(segment):
                                        segments.append(segment)
                                        self.stats['dynamic_segments'] += 1
                                    else:
                                        if segment.duration < self.config.min_duration:
                                            self.stats['discarded_short'] += 1
                                        elif segment.avg_ssim >= self.config.static_threshold:
                                            self.stats['discarded_static'] += 1

                                current_segment_start = batch_frame_idx
                                dynamic_frame_count = 0
                                ssim_buffer = []
                            else:
                                dynamic_frame_count += 1

                        # ë°°ì¹˜ ì´ˆê¸°í™”
                        frame_batch.clear()
                        frame_indices.clear()

                    except Exception as e:
                        # GPU ì˜¤ë¥˜ ì²˜ë¦¬ (OOM ë“±)
                        import torch
                        if isinstance(e, torch.cuda.OutOfMemoryError):
                            print(f"âš ï¸ GPU ë©”ëª¨ë¦¬ ë¶€ì¡±, ë°°ì¹˜ í¬ê¸° {BATCH_SIZE} â†’ {BATCH_SIZE // 2}ë¡œ ê°ì†Œ")
                            BATCH_SIZE = max(1, BATCH_SIZE // 2)
                        else:
                            print(f"âš ï¸ GPU ë°°ì¹˜ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")

                        # í˜„ì¬ ë°°ì¹˜ ë‹¨ì¼ ì²˜ë¦¬ë¡œ í´ë°±
                        for i, (pf, cf) in enumerate(frame_batch):
                            ssim_score = self.calculate_ssim(pf, cf)
                            ssim_buffer.append(ssim_score)
                        frame_batch.clear()
                        frame_indices.clear()

                # prev_frame ì—…ë°ì´íŠ¸ (ë°°ì¹˜ ëª¨ë“œ)
                prev_frame = current_frame
                continue  # ë°°ì¹˜ ëª¨ë“œì—ì„œëŠ” ì•„ë˜ ë‹¨ì¼ ì²˜ë¦¬ ìŠ¤í‚µ

            # ë‹¨ì¼ í”„ë ˆì„ ì²˜ë¦¬ ëª¨ë“œ (CPU ë˜ëŠ” ë°°ì¹˜ ë¯¸ì‚¬ìš©)
            ssim_score = self.calculate_ssim(prev_frame, current_frame)
            ssim_buffer.append(ssim_score)

            # ì¥ë©´ ì „í™˜ ê°ì§€ (scene_threshold ì´í•˜)
            if ssim_score < self.config.scene_change_threshold:
                self.stats['scene_changes'] += 1

                # ì´ì „ ì„¸ê·¸ë¨¼íŠ¸ ì €ì¥ (ì¡°ê±´ ì¶©ì¡± ì‹œ)
                if dynamic_frame_count >= self.config.min_dynamic_frames:
                    segment = self._create_segment(
                        current_segment_start,
                        frame_idx - 1,
                        fps,
                        ssim_buffer[:-1]
                    )

                    if self._is_valid_segment(segment):
                        segments.append(segment)
                        self.stats['dynamic_segments'] += 1
                    else:
                        if segment.duration < self.config.min_duration:
                            self.stats['discarded_short'] += 1
                        elif segment.avg_ssim >= self.config.static_threshold:
                            self.stats['discarded_static'] += 1

                # ìƒˆ ì„¸ê·¸ë¨¼íŠ¸ ì‹œì‘
                current_segment_start = frame_idx
                dynamic_frame_count = 0
                ssim_buffer = []

            # ë™ì  êµ¬ê°„ ì¹´ìš´íŠ¸ (static_threshold ë¯¸ë§Œì´ë©´ ëª¨ë‘ ë™ì )
            elif ssim_score < self.config.static_threshold:
                dynamic_frame_count += 1

            # ìµœëŒ€ ê¸¸ì´ ì´ˆê³¼ ì‹œ ì„¸ê·¸ë¨¼íŠ¸ ë¶„í• 
            segment_frames = frame_idx - current_segment_start
            segment_duration = segment_frames / fps

            if segment_duration >= self.config.max_duration:
                if dynamic_frame_count >= self.config.min_dynamic_frames:
                    segment = self._create_segment(
                        current_segment_start,
                        frame_idx,
                        fps,
                        ssim_buffer
                    )

                    if self._is_valid_segment(segment):
                        segments.append(segment)
                        self.stats['dynamic_segments'] += 1

                current_segment_start = frame_idx
                dynamic_frame_count = 0
                ssim_buffer = []

            # ìµœëŒ€ ì„¸ê·¸ë¨¼íŠ¸ ìˆ˜ ë„ë‹¬
            if (self.config.max_segments and
                len(segments) >= self.config.max_segments):
                print(f"\nâš ï¸ ìµœëŒ€ ì„¸ê·¸ë¨¼íŠ¸ ìˆ˜({self.config.max_segments})ì— ë„ë‹¬í–ˆìŠµë‹ˆë‹¤.")
                break

            prev_frame = current_frame

        # ë°°ì¹˜ ëª¨ë“œì—ì„œ ë‚¨ì€ í”„ë ˆì„ ì²˜ë¦¬
        if use_batch_processing and len(frame_batch) > 0:
            try:
                import torch
                ssim_scores = self._calculate_ssim_gpu_batch(frame_batch)

                for batch_idx, ssim_score in enumerate(ssim_scores):
                    ssim_buffer.append(ssim_score)

                    batch_frame_idx = frame_indices[batch_idx]
                    if ssim_score < self.config.scene_change_threshold:
                        self.stats['scene_changes'] += 1

                        if dynamic_frame_count >= self.config.min_dynamic_frames:
                            segment = self._create_segment(
                                current_segment_start,
                                batch_frame_idx - 1,
                                fps,
                                ssim_buffer[:-1]
                            )

                            if self._is_valid_segment(segment):
                                segments.append(segment)
                                self.stats['dynamic_segments'] += 1

                        current_segment_start = batch_frame_idx
                        dynamic_frame_count = 0
                        ssim_buffer = []
                    else:
                        dynamic_frame_count += 1

            except Exception as e:
                print(f"âš ï¸ ë‚¨ì€ ë°°ì¹˜ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")

        # ë§ˆì§€ë§‰ ì„¸ê·¸ë¨¼íŠ¸ ì²˜ë¦¬
        if dynamic_frame_count >= self.config.min_dynamic_frames:
            segment = self._create_segment(
                current_segment_start,
                frame_idx,
                fps,
                ssim_buffer
            )

            if self._is_valid_segment(segment):
                segments.append(segment)
                self.stats['dynamic_segments'] += 1

        cap.release()

        print(f"\nâœ… ì„¸ê·¸ë¨¼íŠ¸ íƒì§€ ì™„ë£Œ!")
        self._print_stats()

        return segments

    def _create_segment(
        self,
        start_frame: int,
        end_frame: int,
        fps: float,
        ssim_scores: List[float]
    ) -> VideoSegment:
        """ì„¸ê·¸ë¨¼íŠ¸ ê°ì²´ ìƒì„±"""
        start_time = start_frame / fps
        end_time = end_frame / fps
        duration = end_time - start_time
        avg_ssim = np.mean(ssim_scores) if ssim_scores else 0.0

        return VideoSegment(
            start_frame=start_frame,
            end_frame=end_frame,
            start_time=start_time,
            end_time=end_time,
            duration=duration,
            avg_ssim=avg_ssim
        )

    def _is_valid_segment(self, segment: VideoSegment) -> bool:
        """ì„¸ê·¸ë¨¼íŠ¸ ìœ íš¨ì„± ê²€ì¦"""
        # ìµœì†Œ ê¸¸ì´ ì²´í¬
        if segment.duration < self.config.min_duration:
            return False

        # ì •ì  êµ¬ê°„ ì²´í¬ (í‰ê·  SSIMì´ static_threshold ì´ìƒì´ë©´ ì œì™¸)
        if segment.avg_ssim >= self.config.static_threshold:
            return False

        return True

    def export_segments(
        self,
        video_path: Path,
        segments: List[VideoSegment],
        output_dir: Path,
        progress_callback=None
    ) -> List[Path]:
        """
        ì„¸ê·¸ë¨¼íŠ¸ë¥¼ ê°œë³„ ë¹„ë””ì˜¤ íŒŒì¼ë¡œ ì €ì¥ (ffmpeg ì‚¬ìš©)

        Args:
            video_path: ì›ë³¸ ë¹„ë””ì˜¤ ê²½ë¡œ
            segments: ì„¸ê·¸ë¨¼íŠ¸ ë¦¬ìŠ¤íŠ¸
            output_dir: ì¶œë ¥ ë””ë ‰í† ë¦¬
            progress_callback: ì§„í–‰ ìƒí™© ì½œë°±

        Returns:
            ì €ì¥ëœ ë¹„ë””ì˜¤ íŒŒì¼ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸
        """
        # ffmpeg í™•ì¸ ë° ìë™ ì„¤ì¹˜
        if not check_and_install_ffmpeg():
            raise RuntimeError(
                "ffmpegë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. "
                "í„°ë¯¸ë„ì„ ì¬ì‹œì‘í•˜ê±°ë‚˜ ìˆ˜ë™ìœ¼ë¡œ ì„¤ì¹˜í•´ì£¼ì„¸ìš”."
            )

        output_dir.mkdir(parents=True, exist_ok=True)

        saved_paths = []

        print(f"\nğŸ¬ ì„¸ê·¸ë¨¼íŠ¸ ë¹„ë””ì˜¤ ìƒì„± ì¤‘ (ffmpeg)...")

        for idx, segment in enumerate(segments):
            output_path = output_dir / f"segment_{idx+1:03d}.mp4"

            # ffmpegë¡œ ë¹„ë””ì˜¤ ìë¥´ê¸° (ì¬ì¸ì½”ë”© ì—†ì´ ë¹ ë¥´ê²Œ)
            cmd = [
                'ffmpeg',
                '-i', str(video_path),
                '-ss', str(segment.start_time),
                '-to', str(segment.end_time),
                '-c', 'copy',
                '-y',  # ë®ì–´ì“°ê¸°
                str(output_path)
            ]

            try:
                subprocess.run(cmd, check=True, capture_output=True, text=True)
                saved_paths.append(output_path)

                if progress_callback:
                    progress_callback(idx + 1, len(segments))

                print(f"   âœ“ segment_{idx+1:03d}.mp4 ({segment.duration:.1f}ì´ˆ, "
                      f"SSIM: {segment.avg_ssim:.3f})")
            except subprocess.CalledProcessError as e:
                print(f"   âš ï¸ segment_{idx+1:03d}.mp4 ìƒì„± ì‹¤íŒ¨: {e.stderr}")

        # ì±„íƒë˜ì§€ ì•Šì€ êµ¬ê°„ ì €ì¥ (ì‹¤í—˜ ê¸°ëŠ¥)
        if self.config.save_discarded:
            self._export_discarded_segments(video_path, segments, output_dir)

        print(f"\nâœ… {len(saved_paths)}ê°œ ì„¸ê·¸ë¨¼íŠ¸ ì €ì¥ ì™„ë£Œ!")
        return saved_paths

    def _export_discarded_segments(
        self,
        video_path: Path,
        accepted_segments: List[VideoSegment],
        output_dir: Path
    ):
        """
        ì±„íƒë˜ì§€ ì•Šì€ êµ¬ê°„ì„ else í´ë”ì— ì €ì¥

        Args:
            video_path: ì›ë³¸ ë¹„ë””ì˜¤ ê²½ë¡œ
            accepted_segments: ì±„íƒëœ ì„¸ê·¸ë¨¼íŠ¸ ë¦¬ìŠ¤íŠ¸
            output_dir: ì¶œë ¥ ë””ë ‰í† ë¦¬
        """
        # ffmpeg í™•ì¸ (ì´ë¯¸ export_segmentsì—ì„œ ì²´í¬í–ˆìœ¼ë¯€ë¡œ ì¬í™•ì¸ë§Œ)
        if not check_and_install_ffmpeg():
            print("âš ï¸ ffmpegë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ì–´ ì±„íƒë˜ì§€ ì•Šì€ êµ¬ê°„ ì €ì¥ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
            return

        # else í´ë” ìƒì„±
        else_dir = output_dir / "else"
        else_dir.mkdir(exist_ok=True)

        # ë¹„ë””ì˜¤ ì´ ê¸¸ì´ ê°€ì ¸ì˜¤ê¸°
        cap = cv2.VideoCapture(str(video_path))
        fps = cap.get(cv2.CAP_PROP_FPS)
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        total_duration = total_frames / fps
        cap.release()

        print(f"\nğŸ“¦ ì±„íƒë˜ì§€ ì•Šì€ êµ¬ê°„ ì €ì¥ ì¤‘...")

        # ì±„íƒëœ êµ¬ê°„ì„ ì‹œê°„ ìˆœìœ¼ë¡œ ì •ë ¬
        sorted_segments = sorted(accepted_segments, key=lambda s: s.start_time)

        # ë¹ˆ êµ¬ê°„ ì°¾ê¸°
        discarded_segments = []
        prev_end_time = 0.0

        for segment in sorted_segments:
            if segment.start_time > prev_end_time + 0.1:  # 0.1ì´ˆ ì´ìƒ ê³µë°±
                discarded_segments.append((prev_end_time, segment.start_time))
            prev_end_time = segment.end_time

        # ë§ˆì§€ë§‰ êµ¬ê°„ ì´í›„
        if prev_end_time < total_duration - 0.1:
            discarded_segments.append((prev_end_time, total_duration))

        # ë¹ˆ êµ¬ê°„ ì €ì¥
        for idx, (start_time, end_time) in enumerate(discarded_segments):
            output_path = else_dir / f"discarded_{idx+1:03d}.mp4"
            duration = end_time - start_time

            cmd = [
                'ffmpeg',
                '-i', str(video_path),
                '-ss', str(start_time),
                '-to', str(end_time),
                '-c', 'copy',
                '-y',
                str(output_path)
            ]

            try:
                subprocess.run(cmd, check=True, capture_output=True, text=True)
                print(f"   âœ“ discarded_{idx+1:03d}.mp4 ({duration:.1f}ì´ˆ)")
            except subprocess.CalledProcessError as e:
                print(f"   âš ï¸ discarded_{idx+1:03d}.mp4 ìƒì„± ì‹¤íŒ¨: {e.stderr}")

        print(f"âœ… {len(discarded_segments)}ê°œ ì±„íƒë˜ì§€ ì•Šì€ êµ¬ê°„ ì €ì¥ ì™„ë£Œ!")

    def save_metadata(
        self,
        output_dir: Path,
        video_path: Path,
        segments: List[VideoSegment]
    ):
        """ë©”íƒ€ë°ì´í„° ì €ì¥"""
        metadata = {
            'source_video': str(video_path),
            'timestamp': datetime.now().isoformat(),
            'config': {
                'scene_change_threshold': self.config.scene_change_threshold,
                'static_threshold': self.config.static_threshold,
                'min_duration': self.config.min_duration,
                'max_duration': self.config.max_duration,
                'ssim_scale': self.config.ssim_scale,
                'frame_skip': self.config.frame_skip,
                'use_gpu': self.config.use_gpu,
            },
            'stats': self.stats,
            'segments': [
                {
                    'index': i + 1,
                    'filename': f"segment_{i+1:03d}.mp4",
                    'start_frame': seg.start_frame,
                    'end_frame': seg.end_frame,
                    'start_time': seg.start_time,
                    'end_time': seg.end_time,
                    'duration': seg.duration,
                    'avg_ssim': seg.avg_ssim
                }
                for i, seg in enumerate(segments)
            ]
        }

        metadata_path = output_dir / "segments_metadata.json"
        with open(metadata_path, 'w', encoding='utf-8') as f:
            json.dump(metadata, f, ensure_ascii=False, indent=2)

        print(f"\nğŸ’¾ ë©”íƒ€ë°ì´í„° ì €ì¥: {metadata_path}")

    def _print_stats(self):
        """í†µê³„ ì¶œë ¥"""
        print(f"\nğŸ“Š ì„¸ê·¸ë©˜í…Œì´ì…˜ í†µê³„:")
        print(f"   - ì´ í”„ë ˆì„: {self.stats['total_frames']:,}ê°œ")
        print(f"   - ì¥ë©´ ì „í™˜: {self.stats['scene_changes']:,}ê°œ")
        print(f"   - ë™ì  ì„¸ê·¸ë¨¼íŠ¸: {self.stats['dynamic_segments']:,}ê°œ")
        print(f"   - ì œì™¸ (ì§§ìŒ): {self.stats['discarded_short']:,}ê°œ")
        print(f"   - ì œì™¸ (ì •ì /ì ìˆ˜): {self.stats['discarded_static']:,}ê°œ")

        # SSIM ì„±ëŠ¥ í†µê³„
        gpu_count = self.stats['ssim_gpu_count']
        cpu_count = self.stats['ssim_cpu_count']
        gpu_time = self.stats['ssim_gpu_time']
        cpu_time = self.stats['ssim_cpu_time']

        if gpu_count > 0 or cpu_count > 0:
            print(f"\nâš¡ SSIM ì„±ëŠ¥ í†µê³„:")
            if gpu_count > 0:
                avg_gpu_time = (gpu_time / gpu_count) * 1000  # ms
                print(f"   - GPU SSIM: {gpu_count:,}íšŒ, í‰ê·  {avg_gpu_time:.2f}ms/í”„ë ˆì„, ì´ {gpu_time:.2f}ì´ˆ")
            if cpu_count > 0:
                avg_cpu_time = (cpu_time / cpu_count) * 1000  # ms
                print(f"   - CPU SSIM: {cpu_count:,}íšŒ, í‰ê·  {avg_cpu_time:.2f}ms/í”„ë ˆì„, ì´ {cpu_time:.2f}ì´ˆ")
            if gpu_count > 0 and cpu_count > 0:
                speedup = (cpu_time / cpu_count) / (gpu_time / gpu_count)
                print(f"   - GPU ê°€ì† ë°°ìœ¨: {speedup:.1f}x")


def main():
    parser = argparse.ArgumentParser(
        description="SSIM ê¸°ë°˜ ìŠ¤ë§ˆíŠ¸ ë¹„ë””ì˜¤ ì„¸ê·¸ë©˜í…Œì´ì…˜"
    )
    parser.add_argument(
        '--input',
        type=Path,
        required=True,
        help="ì…ë ¥ ë¹„ë””ì˜¤ ê²½ë¡œ"
    )
    parser.add_argument(
        '--output',
        type=Path,
        required=True,
        help="ì¶œë ¥ ë””ë ‰í† ë¦¬"
    )
    parser.add_argument(
        '--scene-threshold',
        type=float,
        default=0.3,
        help="ì¥ë©´ ì „í™˜ ì„ê³„ê°’ (ê¸°ë³¸: 0.3)"
    )
    parser.add_argument(
        '--static-threshold',
        type=float,
        default=0.95,
        help="ì •ì  êµ¬ê°„ ì„ê³„ê°’ - ì´ë³´ë‹¤ ë†’ìœ¼ë©´ ì ìˆ˜ êµ¬ê°„ìœ¼ë¡œ ì œì™¸ (ê¸°ë³¸: 0.95)"
    )
    parser.add_argument(
        '--min-duration',
        type=float,
        default=5.0,
        help="ìµœì†Œ ì„¸ê·¸ë¨¼íŠ¸ ê¸¸ì´ ì´ˆ (ê¸°ë³¸: 5.0)"
    )
    parser.add_argument(
        '--max-duration',
        type=float,
        default=60.0,
        help="ìµœëŒ€ ì„¸ê·¸ë¨¼íŠ¸ ê¸¸ì´ ì´ˆ (ê¸°ë³¸: 60.0)"
    )
    parser.add_argument(
        '--max-segments',
        type=int,
        default=None,
        help="ìµœëŒ€ ì„¸ê·¸ë¨¼íŠ¸ ìˆ˜ (ê¸°ë³¸: ë¬´ì œí•œ)"
    )
    parser.add_argument(
        '--ssim-scale',
        type=float,
        default=1.0,
        help="SSIM ê³„ì‚° ì‹œ í•´ìƒë„ ìŠ¤ì¼€ì¼ (0.25=4ë°° ë¹ ë¦„, 1.0=ì›ë³¸, ê¸°ë³¸: 1.0, ì¶œë ¥ì€ í•­ìƒ ì›ë³¸ í•´ìƒë„)"
    )
    parser.add_argument(
        '--frame-skip',
        type=int,
        default=1,
        help="í”„ë ˆì„ ìŠ¤í‚µ (1=ëª¨ë“  í”„ë ˆì„, 3=3í”„ë ˆì„ë§ˆë‹¤, ê¸°ë³¸: 1)"
    )
    parser.add_argument(
        '--save-discarded',
        action='store_true',
        help="ì±„íƒë˜ì§€ ì•Šì€ êµ¬ê°„ë„ else í´ë”ì— ì €ì¥ (ì‹¤í—˜ ê¸°ëŠ¥)"
    )
    parser.add_argument(
        '--use-gpu',
        action='store_true',
        help="GPU ê°€ì† ì‚¬ìš© (CUDA ì‚¬ìš© ê°€ëŠ¥ ì‹œ)"
    )

    args = parser.parse_args()

    # ì„¤ì • ìƒì„±
    config = SegmentConfig(
        scene_change_threshold=args.scene_threshold,
        static_threshold=args.static_threshold,
        min_duration=args.min_duration,
        max_duration=args.max_duration,
        max_segments=args.max_segments,
        ssim_scale=args.ssim_scale,
        frame_skip=args.frame_skip,
        save_discarded=args.save_discarded,
        use_gpu=args.use_gpu
    )

    # ì„¸ê·¸ë©˜í„° ìƒì„±
    segmenter = VideoSegmenter(config)

    # ì§„í–‰ ìƒí™© ì½œë°±
    def progress_callback(current, total):
        print(f"   ì§„í–‰: {current:,} / {total:,} ({current / total * 100:.1f}%)", end='\r')

    try:
        # ì„¸ê·¸ë¨¼íŠ¸ íƒì§€
        segments = segmenter.detect_segments(args.input, progress_callback)

        if not segments:
            print("\nâŒ ìœ íš¨í•œ ì„¸ê·¸ë¨¼íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return 1

        # ì„¸ê·¸ë¨¼íŠ¸ ë¹„ë””ì˜¤ ìƒì„±
        saved_paths = segmenter.export_segments(
            args.input,
            segments,
            args.output,
            progress_callback
        )

        # ë©”íƒ€ë°ì´í„° ì €ì¥
        segmenter.save_metadata(args.output, args.input, segments)

        print(f"\nâœ… ì™„ë£Œ!")
        print(f"   ì¶œë ¥ ë””ë ‰í† ë¦¬: {args.output}")
        print(f"   ì„¸ê·¸ë¨¼íŠ¸ ìˆ˜: {len(saved_paths)}ê°œ")

        total_duration = sum(seg.duration for seg in segments)
        print(f"   ì´ ê¸¸ì´: {total_duration / 60:.1f}ë¶„")

    except Exception as e:
        print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
        return 1

    return 0


if __name__ == '__main__':
    exit(main())
