#!/usr/bin/env python3
"""
Optical Flow ê¸°ë°˜ ìŠ¤ë§ˆíŠ¸ ë¹„ë””ì˜¤ ì„¸ê·¸ë©˜í…Œì´ì…˜
ê²Œì„ ì˜ìƒì„ ì›€ì§ì„ íŒ¨í„´ì— ë”°ë¼ ë¶„í• í•˜ì—¬ YOLO í•™ìŠµ ë°ì´í„° ìµœì í™”

ì»¤íŒ… ì „ëµ:
- ì›€ì§ì„ ì ì€ êµ¬ê°„: ë²„ë¦¼ (ì˜¤ë²„í”¼íŒ… ë°©ì§€)
- ì¥ë©´ ì „í™˜ êµ¬ê°„: ìš°ì„  ì„ íƒ (ì»¨í…ì¸  ì…ì¥/ì¢…ë£Œ ê°ì§€)
- UI ê³ ì • + ë°°ê²½ ë™ì  êµ¬ê°„: ì ë‹¹ëŸ‰ ì„ íƒ (UI ì¶”ì  í•™ìŠµ)

ì‚¬ìš©ë²•:
    python tools/video_segmenter.py --input datasets/raw/gameplay.mp4 \
                                     --output datasets/clips/ \
                                     --motion-low 2.0 \
                                     --motion-high 15.0 \
                                     --min-duration 5
"""

import argparse
import cv2
import numpy as np
from pathlib import Path
from typing import List, Tuple, Optional
from dataclasses import dataclass
import json
from datetime import datetime
import subprocess
import shutil
import sys
import os


def refresh_system_path():
    """
    ì‹œìŠ¤í…œ PATH í™˜ê²½ë³€ìˆ˜ë¥¼ ë ˆì§€ìŠ¤íŠ¸ë¦¬ì—ì„œ ìƒˆë¡œê³ ì¹¨ (Windows ì „ìš©)
    winget ì„¤ì¹˜ í›„ í˜„ì¬ í”„ë¡œì„¸ìŠ¤ì—ì„œ PATHë¥¼ ì¦‰ì‹œ ì‚¬ìš©í•˜ê¸° ìœ„í•¨
    """
    if sys.platform != 'win32':
        return

    try:
        import winreg
        import os

        # ì‹œìŠ¤í…œ PATH ì½ê¸°
        with winreg.OpenKey(winreg.HKEY_LOCAL_MACHINE,
                           r'SYSTEM\CurrentControlSet\Control\Session Manager\Environment',
                           0, winreg.KEY_READ) as key:
            system_path, _ = winreg.QueryValueEx(key, 'Path')

        # ì‚¬ìš©ì PATH ì½ê¸°
        with winreg.OpenKey(winreg.HKEY_CURRENT_USER,
                           r'Environment',
                           0, winreg.KEY_READ) as key:
            try:
                user_path, _ = winreg.QueryValueEx(key, 'Path')
            except FileNotFoundError:
                user_path = ''

        # í˜„ì¬ í”„ë¡œì„¸ìŠ¤ì˜ PATH ì—…ë°ì´íŠ¸
        combined_path = f"{user_path};{system_path}" if user_path else system_path
        os.environ['PATH'] = combined_path

    except Exception as e:
        # PATH ìƒˆë¡œê³ ì¹¨ ì‹¤íŒ¨ëŠ” ì¹˜ëª…ì ì´ì§€ ì•Šìœ¼ë¯€ë¡œ ë¬´ì‹œ
        pass


def check_and_install_ffmpeg() -> bool:
    """
    ffmpeg ì„¤ì¹˜ ì—¬ë¶€ í™•ì¸ ë° ìë™ ì„¤ì¹˜

    Returns:
        bool: ffmpegê°€ ì‚¬ìš© ê°€ëŠ¥í•˜ë©´ True, ì„¤ì¹˜ ì‹¤íŒ¨í•˜ë©´ False
    """
    # ffmpegê°€ ì´ë¯¸ PATHì— ìˆëŠ”ì§€ í™•ì¸
    if shutil.which('ffmpeg') is not None:
        return True

    print("âš ï¸ ffmpegë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    print("ğŸ”§ ffmpegë¥¼ ìë™ìœ¼ë¡œ ì„¤ì¹˜í•©ë‹ˆë‹¤ (winget ì‚¬ìš©)...")

    try:
        # wingetìœ¼ë¡œ ffmpeg ì„¤ì¹˜ ì‹œë„
        result = subprocess.run(
            ['winget', 'install', 'Gyan.FFmpeg', '--accept-source-agreements', '--accept-package-agreements'],
            capture_output=True,
            text=True,
            timeout=300  # 5ë¶„ íƒ€ì„ì•„ì›ƒ
        )

        if result.returncode == 0:
            print("âœ… ffmpeg ì„¤ì¹˜ ì™„ë£Œ!")

            # PATH ìƒˆë¡œê³ ì¹¨ ì‹œë„
            print("ğŸ”„ PATH í™˜ê²½ë³€ìˆ˜ ìƒˆë¡œê³ ì¹¨ ì¤‘...")
            refresh_system_path()

            # ì„¤ì¹˜ í›„ ë‹¤ì‹œ í™•ì¸
            if shutil.which('ffmpeg') is not None:
                print("âœ… ffmpegë¥¼ ë°”ë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤!")
                return True
            else:
                print("   âš ï¸ ì„¤ì¹˜ëŠ” ì™„ë£Œë˜ì—ˆìœ¼ë‚˜ PATHì—ì„œ ffmpegë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                print("   â„¹ï¸ ë‹¤ìŒ ì¤‘ í•˜ë‚˜ë¥¼ ì‹œë„í•´ì£¼ì„¸ìš”:")
                print("      1. í„°ë¯¸ë„ì„ ì¬ì‹œì‘í•œ í›„ ë‹¤ì‹œ ì‹¤í–‰")
                print("      2. ì‹œìŠ¤í…œì„ ì¬ë¶€íŒ…")
                return False
        else:
            print(f"âŒ ffmpeg ì„¤ì¹˜ ì‹¤íŒ¨")
            if result.stderr:
                print(f"   ì˜¤ë¥˜ ë©”ì‹œì§€: {result.stderr[:200]}")
            print("   â„¹ï¸ ìˆ˜ë™ ì„¤ì¹˜ ë°©ë²•:")
            print("      1. í„°ë¯¸ë„ì—ì„œ 'winget install Gyan.FFmpeg' ì‹¤í–‰")
            print("      2. ë˜ëŠ” https://www.gyan.dev/ffmpeg/builds/ ì—ì„œ ë‹¤ìš´ë¡œë“œ")
            return False

    except FileNotFoundError:
        print("âŒ wingetì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        print("   â„¹ï¸ Windows 10 1809 ì´ìƒ ë˜ëŠ” Windows 11ì´ í•„ìš”í•©ë‹ˆë‹¤.")
        print("   â„¹ï¸ ìˆ˜ë™ ì„¤ì¹˜: https://www.gyan.dev/ffmpeg/builds/")
        return False
    except subprocess.TimeoutExpired:
        print("âŒ ffmpeg ì„¤ì¹˜ ì‹œê°„ ì´ˆê³¼ (5ë¶„)")
        print("   â„¹ï¸ ë„¤íŠ¸ì›Œí¬ ìƒíƒœë¥¼ í™•ì¸í•˜ê³  ìˆ˜ë™ìœ¼ë¡œ ì„¤ì¹˜í•´ì£¼ì„¸ìš”.")
        return False
    except Exception as e:
        print(f"âŒ ffmpeg ì„¤ì¹˜ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}")
        return False


class PyAVVideoReader:
    """
    PyAVë¥¼ ì‚¬ìš©í•œ ë¹„ë””ì˜¤ ë¦¬ë” (OpenCVê°€ ì§€ì›í•˜ì§€ ì•ŠëŠ” ì½”ë± ì²˜ë¦¬)
    AV1, H.265, VP9 ë“± ëª¨ë“  FFmpeg ì§€ì› ì½”ë±ì„ ë¬´ì†ì‹¤ë¡œ ì½ì„ ìˆ˜ ìˆìŒ
    """

    def __init__(self, video_path: Path):
        """
        Args:
            video_path: ë¹„ë””ì˜¤ íŒŒì¼ ê²½ë¡œ
        """
        self.video_path = video_path
        self.container = None
        self.video_stream = None
        self.fps = None
        self.total_frames = None
        self.width = None
        self.height = None
        self._frame_generator = None

    def open(self) -> bool:
        """
        ë¹„ë””ì˜¤ íŒŒì¼ ì—´ê¸°

        Returns:
            bool: ì„±ê³µ ì—¬ë¶€
        """
        try:
            import av

            self.container = av.open(str(self.video_path))
            self.video_stream = self.container.streams.video[0]

            # ë¹„ë””ì˜¤ ì •ë³´ ì¶”ì¶œ
            self.fps = float(self.video_stream.average_rate)
            self.total_frames = self.video_stream.frames
            self.width = self.video_stream.width
            self.height = self.video_stream.height

            # total_framesê°€ 0ì´ë©´ durationìœ¼ë¡œ ì¶”ì •
            if self.total_frames == 0 and self.container.duration:
                self.total_frames = int(self.container.duration * self.fps / av.time_base)

            # í”„ë ˆì„ ì œë„ˆë ˆì´í„° ì´ˆê¸°í™”
            self._frame_generator = self.container.decode(video=0)

            print(f"âœ… PyAVë¡œ ë¹„ë””ì˜¤ ì—´ê¸° ì„±ê³µ")
            print(f"   ì½”ë±: {self.video_stream.codec_context.name}")

            return True

        except ImportError:
            print("âš ï¸ PyAVê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            print("   ì„¤ì¹˜ ë°©ë²•: pip install av")
            return False
        except Exception as e:
            print(f"âš ï¸ PyAVë¡œ ë¹„ë””ì˜¤ ì—´ê¸° ì‹¤íŒ¨: {e}")
            return False

    def read(self):
        """
        ë‹¤ìŒ í”„ë ˆì„ ì½ê¸° (OpenCVì˜ cap.read()ì™€ ë™ì¼í•œ ì¸í„°í˜ì´ìŠ¤)

        Returns:
            tuple: (success, frame_bgr) - OpenCV í˜•ì‹ì˜ BGR numpy array
        """
        try:
            frame = next(self._frame_generator)
            # BGR í¬ë§·ìœ¼ë¡œ ë³€í™˜ (OpenCV í˜¸í™˜)
            img = frame.to_ndarray(format='bgr24')
            return True, img
        except StopIteration:
            return False, None
        except Exception as e:
            return False, None

    def grab(self):
        """
        í”„ë ˆì„ì„ ê±´ë„ˆë›°ê¸° (OpenCVì˜ cap.grab()ì™€ ë™ì¼í•œ ì¸í„°í˜ì´ìŠ¤)
        PyAVëŠ” grabì„ ì§ì ‘ ì§€ì›í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ readí•˜ê³  ë²„ë¦¼

        Returns:
            bool: ì„±ê³µ ì—¬ë¶€
        """
        try:
            frame = next(self._frame_generator)
            return True
        except StopIteration:
            return False
        except Exception as e:
            return False

    def release(self):
        """ë¦¬ì†ŒìŠ¤ í•´ì œ"""
        if self.container:
            self.container.close()
            self.container = None

    def isOpened(self) -> bool:
        """ë¹„ë””ì˜¤ê°€ ì—´ë ¤ìˆëŠ”ì§€ í™•ì¸"""
        return self.container is not None


@dataclass
class DynamicRange:
    """ë™ì  êµ¬ê°„ ì •ë³´ (ì •ì  êµ¬ê°„ ì œì™¸)"""
    start_time: float
    end_time: float
    duration: float
    avg_motion: float


@dataclass
class VideoSegment:
    """ìµœì¢… ì¶œë ¥ ì„¸ê·¸ë¨¼íŠ¸ (ê³ ì • ê¸¸ì´ë¡œ ë¶„í• ëœ)"""
    start_time: float
    end_time: float
    duration: float
    avg_motion: float


@dataclass
class SegmentConfig:
    """ì„¸ê·¸ë©˜í…Œì´ì…˜ ì„¤ì • (ê°„ì†Œí™”)"""
    # Motion ê°ì§€
    motion_threshold: float = 2.0        # ì´ë³´ë‹¤ ë‚®ìœ¼ë©´ ì •ì  êµ¬ê°„ (ì œê±°)

    # ìµœì¢… ë¶„í• 
    target_duration: float = 30.0        # ìµœì¢… í´ë¦½ ê¸¸ì´ (ì´ˆ)
    min_dynamic_duration: float = 3.0    # ìµœì†Œ ë™ì  êµ¬ê°„ ê¸¸ì´ (ì´ë³´ë‹¤ ì§§ìœ¼ë©´ ë¬´ì‹œ)

    # ì„±ëŠ¥ ìµœì í™”
    batch_size: int = 32                 # GPU ë°°ì¹˜ í¬ê¸° (ìë™ ì¡°ì • ê°€ëŠ¥)
    flow_scale: float = 0.5              # Optical Flow ê³„ì‚° ì‹œ í•´ìƒë„ ìŠ¤ì¼€ì¼
    frame_skip: int = 1                  # í”„ë ˆì„ ìŠ¤í‚µ (1=ëª¨ë“  í”„ë ˆì„)
    use_gpu: bool = False                # GPU ê°€ì† ì‚¬ìš©

    # ì¶œë ¥ ì„¤ì •
    output_codec: str = "mp4v"           # ì¶œë ¥ ì½”ë±
    output_fps: Optional[int] = None     # ì¶œë ¥ FPS (Noneì´ë©´ ì›ë³¸)


class VideoSegmenter:
    """Optical Flow ê¸°ë°˜ ë¹„ë””ì˜¤ ì„¸ê·¸ë©˜í…Œì´ì…˜"""

    def __init__(self, config: SegmentConfig = None):
        self.config = config or SegmentConfig()
        self.stats = {
            'total_frames': 0,
            'dynamic_frames': 0,        # ë™ì  í”„ë ˆì„ ìˆ˜
            'static_frames': 0,         # ì •ì  í”„ë ˆì„ ìˆ˜
            'dynamic_ranges': 0,        # ë™ì  êµ¬ê°„ ìˆ˜
            'final_segments': 0,        # ìµœì¢… ì„¸ê·¸ë¨¼íŠ¸ ìˆ˜
            'flow_gpu_count': 0,        # GPUë¡œ ê³„ì‚°í•œ Optical Flow íšŸìˆ˜
            'flow_cpu_count': 0,        # CPUë¡œ ê³„ì‚°í•œ Optical Flow íšŸìˆ˜
            'flow_gpu_time': 0.0,       # GPU Flow ì´ ì‹œê°„ (ì´ˆ)
            'flow_cpu_time': 0.0,       # CPU Flow ì´ ì‹œê°„ (ì´ˆ)
        }

        # GPU ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
        self.gpu_available = False
        self.device = None
        self.sobel_x = None  # Sobel X í•„í„° (ì¬ì‚¬ìš©)
        self.sobel_y = None  # Sobel Y í•„í„° (ì¬ì‚¬ìš©)
        self.batch_size = self.config.batch_size  # ë°°ì¹˜ í¬ê¸° (ìë™ ì¡°ì •ë¨)

        if self.config.use_gpu:
            self.gpu_available = self._check_gpu_available()

    def _check_gpu_available(self) -> bool:
        """
        GPU ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸ (CUDA/PyTorch)

        Returns:
            bool: GPU ì‚¬ìš© ê°€ëŠ¥í•˜ë©´ True
        """
        try:
            # 1. PyTorch ì„¤ì¹˜ ê²½ë¡œë¥¼ sys.pathì— ì¶”ê°€
            import sys
            from pathlib import Path
            import os

            # src/utils ê²½ë¡œ ì¶”ê°€ (PyTorchInstaller importìš©)
            if getattr(sys, 'frozen', False):
                # PyInstaller íŒ¨í‚¤ì§• í™˜ê²½
                utils_dir = Path(sys.executable).parent / "_internal" / "src"
            else:
                # ê°œë°œ í™˜ê²½
                script_dir = Path(__file__).parent.parent
                utils_dir = script_dir / "src"

            if utils_dir.exists() and str(utils_dir) not in sys.path:
                sys.path.insert(0, str(utils_dir))

            # 2. PyTorch ì„¤ì¹˜ í™•ì¸
            try:
                from utils.pytorch_installer import PyTorchInstaller
                installer = PyTorchInstaller.get_instance()

                if not installer.is_pytorch_installed():
                    print("âš ï¸ PyTorchê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. CPU ëª¨ë“œë¡œ ì‹¤í–‰í•©ë‹ˆë‹¤.")
                    print("   GPU ê°€ì†ì„ ì‚¬ìš©í•˜ë ¤ë©´ GUIì—ì„œ 'GPU ê°€ì†' ì²´í¬ë°•ìŠ¤ë¥¼ í™œì„±í™”í•˜ì„¸ìš”.")
                    return False

                # sys.pathì— PyTorch ê²½ë¡œ ì¶”ê°€
                installer.add_to_path()

            except ImportError:
                # PyTorchInstallerë¥¼ ì°¾ì„ ìˆ˜ ì—†ëŠ” ê²½ìš° (ì´ì „ ë²„ì „ í˜¸í™˜ì„±)
                print("âš ï¸ PyTorchInstallerë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì‹œìŠ¤í…œ PyTorchë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")

            # 3. PyTorch import ì‹œë„
            import torch

            if torch.cuda.is_available():
                self.device = torch.device('cuda')
                gpu_name = torch.cuda.get_device_name(0)
                print(f"âœ… GPU ê°ì§€ë¨: {gpu_name}")

                # 4. ì‹¤ì œ GPU í…ì„œ ìƒì„± ë° ì—°ì‚° í…ŒìŠ¤íŠ¸
                print("ğŸ” GPU ì´ˆê¸°í™” í…ŒìŠ¤íŠ¸ ì¤‘...")
                try:
                    # ì‘ì€ í–‰ë ¬ ê³±ì…ˆìœ¼ë¡œ GPU ì‘ë™ í™•ì¸
                    test_tensor = torch.randn(100, 100, device=self.device)
                    result = test_tensor @ test_tensor.T
                    torch.cuda.synchronize()  # GPU ì‘ì—… ì™„ë£Œ ëŒ€ê¸°

                    # ë©”ëª¨ë¦¬ ì •ë³´ í™•ì¸
                    memory_allocated = torch.cuda.memory_allocated(0) / 1024 / 1024  # MB
                    memory_reserved = torch.cuda.memory_reserved(0) / 1024 / 1024    # MB

                    print(f"âœ… GPU ê°€ì† í™œì„±í™” ì„±ê³µ!")
                    print(f"   - GPU ë©”ëª¨ë¦¬ í• ë‹¹: {memory_allocated:.1f} MB")
                    print(f"   - GPU ë©”ëª¨ë¦¬ ì˜ˆì•½: {memory_reserved:.1f} MB")

                    # Sobel í•„í„° ë¯¸ë¦¬ ìƒì„± (GPU ë©”ëª¨ë¦¬ì— ìƒì£¼)
                    self.sobel_x = torch.tensor([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]],
                                               dtype=torch.float32, device=self.device).view(1, 1, 3, 3)
                    self.sobel_y = torch.tensor([[-1, -2, -1], [0, 0, 0], [1, 2, 1]],
                                               dtype=torch.float32, device=self.device).view(1, 1, 3, 3)
                    print("âœ… GPU Sobel í•„í„° ì´ˆê¸°í™” ì™„ë£Œ")

                    return True

                except RuntimeError as e:
                    print(f"âŒ GPU í…ì„œ ìƒì„± ì‹¤íŒ¨: {e}")
                    print("   CPU ëª¨ë“œë¡œ ì‹¤í–‰í•©ë‹ˆë‹¤.")
                    return False
                except Exception as e:
                    print(f"âŒ GPU ì´ˆê¸°í™” í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
                    print("   CPU ëª¨ë“œë¡œ ì‹¤í–‰í•©ë‹ˆë‹¤.")
                    return False
            else:
                print("âš ï¸ CUDAë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. CPU ëª¨ë“œë¡œ ì‹¤í–‰í•©ë‹ˆë‹¤.")
                return False

        except ImportError:
            print("âš ï¸ PyTorchê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. CPU ëª¨ë“œë¡œ ì‹¤í–‰í•©ë‹ˆë‹¤.")
            print("   GPU ê°€ì†ì„ ì‚¬ìš©í•˜ë ¤ë©´ GUIì—ì„œ 'GPU ê°€ì†' ì²´í¬ë°•ìŠ¤ë¥¼ í™œì„±í™”í•˜ì„¸ìš”.")
            return False
        except (OSError, RuntimeError) as e:
            # DLL ë¡œë”© ì‹¤íŒ¨ ë˜ëŠ” CUDA ì´ˆê¸°í™” ì˜¤ë¥˜
            print(f"âš ï¸ PyTorch ë¡œë”© ì‹¤íŒ¨: {e}")
            print("   CPU ëª¨ë“œë¡œ ì‹¤í–‰í•©ë‹ˆë‹¤.")
            print("   í•´ê²° ë°©ë²•:")
            print("   1. GUIì—ì„œ 'GPU ê°€ì†' ì²´í¬ë°•ìŠ¤ë¥¼ ë‹¤ì‹œ í™œì„±í™”í•˜ì„¸ìš”.")
            print("   2. PyTorch ì¬ì„¤ì¹˜: ì„¤ì • ë©”ë‰´ì—ì„œ 'PyTorch ì¬ì„¤ì¹˜' í´ë¦­")
            return False
        except Exception as e:
            # ê¸°íƒ€ ëª¨ë“  ì˜ˆì™¸
            print(f"âš ï¸ GPU ì´ˆê¸°í™” ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}")
            print("   CPU ëª¨ë“œë¡œ ì‹¤í–‰í•©ë‹ˆë‹¤.")
            return False

    def calculate_motion(
        self,
        prev_frame: np.ndarray,
        current_frame: np.ndarray
    ) -> float:
        """
        Optical Flow ê¸°ë°˜ ì›€ì§ì„ í¬ê¸° ê³„ì‚°

        Returns:
            motion_score: í‰ê·  optical flow í¬ê¸° (í”½ì…€/í”„ë ˆì„)
        """
        import time

        # í•´ìƒë„ ì¶•ì†Œ (ì„¤ì •ëœ ê²½ìš°)
        if self.config.flow_scale < 1.0:
            h, w = prev_frame.shape[:2]
            new_h = int(h * self.config.flow_scale)
            new_w = int(w * self.config.flow_scale)
            prev_small = cv2.resize(prev_frame, (new_w, new_h), interpolation=cv2.INTER_AREA)
            curr_small = cv2.resize(current_frame, (new_w, new_h), interpolation=cv2.INTER_AREA)
        else:
            prev_small = prev_frame
            curr_small = current_frame

        # GPU ê°€ì† ì‚¬ìš© (PyTorch + CUDA Optical Flow)
        if self.gpu_available:
            try:
                start_time = time.perf_counter()
                motion_score = self._calculate_flow_gpu(prev_small, curr_small)
                elapsed = time.perf_counter() - start_time

                self.stats['flow_gpu_count'] += 1
                self.stats['flow_gpu_time'] += elapsed
                return motion_score
            except (OSError, RuntimeError, Exception) as e:
                print(f"âš ï¸ GPU Optical Flow ê³„ì‚° ì‹¤íŒ¨, CPUë¡œ ì „í™˜: {e}")
                self.gpu_available = False

        # CPU ë²„ì „ (OpenCV Farneback)
        start_time = time.perf_counter()

        # Optical Flow ê³„ì‚°
        prev_gray = cv2.cvtColor(prev_small, cv2.COLOR_BGR2GRAY)
        curr_gray = cv2.cvtColor(curr_small, cv2.COLOR_BGR2GRAY)

        flow = cv2.calcOpticalFlowFarneback(
            prev_gray, curr_gray,
            None,
            pyr_scale=0.5,
            levels=3,
            winsize=15,
            iterations=3,
            poly_n=5,
            poly_sigma=1.2,
            flags=0
        )

        # ì›€ì§ì„ í¬ê¸° (magnitude)
        magnitude = np.sqrt(flow[..., 0]**2 + flow[..., 1]**2)
        motion_score = np.mean(magnitude)

        elapsed = time.perf_counter() - start_time
        self.stats['flow_cpu_count'] += 1
        self.stats['flow_cpu_time'] += elapsed

        return motion_score

    def _calculate_flow_gpu(
        self,
        prev_frame: np.ndarray,
        current_frame: np.ndarray
    ) -> float:
        """
        GPUë¥¼ ì‚¬ìš©í•œ Optical Flow ê³„ì‚° (PyTorch ì™„ì „ GPU êµ¬í˜„)

        Lucas-Kanade ìœˆë„ìš° ê¸°ë°˜ ìµœì†Œì œê³±ë²•ì„ ì‚¬ìš©í•œ optical flow ê³„ì‚°.
        5x5 ìœˆë„ìš° ë‚´ì—ì„œ A^T A [u; v] = -A^T bë¥¼ í’€ì–´ ì‹¤ì œ í”½ì…€ ë‹¨ìœ„ ì´ë™ ë²¡í„° ê³„ì‚°.

        ì •í™•ë„: Farneback ëŒ€ë¹„ 70-80% ìˆ˜ì¤€
        ì†ë„: CPU Farneback ëŒ€ë¹„ 10-20ë°° ë¹ ë¦„
        ì¶œë ¥: ì‹¤ì œ í”½ì…€ ë‹¨ìœ„ magnitude

        Args:
            prev_frame: ì´ì „ í”„ë ˆì„ (BGR)
            current_frame: í˜„ì¬ í”„ë ˆì„ (BGR)

        Returns:
            motion_score (float): í‰ê·  í”½ì…€ ì´ë™ ê±°ë¦¬
        """
        try:
            import torch
            import torch.nn.functional as F

            # BGR -> Grayscale ë³€í™˜ (GPUì—ì„œ)
            # ê°€ì¤‘ì¹˜: B=0.114, G=0.587, R=0.299
            prev_tensor = torch.from_numpy(prev_frame).float().to(self.device)
            curr_tensor = torch.from_numpy(current_frame).float().to(self.device)

            prev_gray = (prev_tensor[..., 0] * 0.114 +
                        prev_tensor[..., 1] * 0.587 +
                        prev_tensor[..., 2] * 0.299)
            curr_gray = (curr_tensor[..., 0] * 0.114 +
                        curr_tensor[..., 1] * 0.587 +
                        curr_tensor[..., 2] * 0.299)

            # Add batch and channel dimensions for conv2d: [H, W] -> [1, 1, H, W]
            prev_gray = prev_gray.unsqueeze(0).unsqueeze(0)
            curr_gray = curr_gray.unsqueeze(0).unsqueeze(0)

            # Spatial gradients (Ix, Iy) - ë¯¸ë¦¬ ìƒì„±ëœ Sobel í•„í„° ì‚¬ìš©
            Ix = F.conv2d(curr_gray, self.sobel_x, padding=1)
            Iy = F.conv2d(curr_gray, self.sobel_y, padding=1)

            # Temporal gradient (It)
            It = curr_gray - prev_gray

            # Lucas-Kanade ìœˆë„ìš° ê¸°ë°˜ ìµœì†Œì œê³±ë²•
            # 5x5 ìœˆë„ìš° ë‚´ì—ì„œ A^T A [u; v] = -A^T b í’€ì´
            window_size = 5

            # ìœˆë„ìš° ë‚´ í•© ê³„ì‚° (avg_pool2dë¡œ êµ¬í˜„)
            # avg_pool2dëŠ” í•©/ìœˆë„ìš°í¬ê¸°ë¥¼ ë°˜í™˜í•˜ë¯€ë¡œ, ìœˆë„ìš° í¬ê¸°ë¥¼ ê³±í•´ì•¼ ì‹¤ì œ í•©
            window_area = window_size * window_size

            Ix2 = F.avg_pool2d(Ix * Ix, window_size, stride=1, padding=window_size//2) * window_area
            Iy2 = F.avg_pool2d(Iy * Iy, window_size, stride=1, padding=window_size//2) * window_area
            IxIy = F.avg_pool2d(Ix * Iy, window_size, stride=1, padding=window_size//2) * window_area
            IxIt = F.avg_pool2d(Ix * It, window_size, stride=1, padding=window_size//2) * window_area
            IyIt = F.avg_pool2d(Iy * It, window_size, stride=1, padding=window_size//2) * window_area

            # 2x2 í–‰ë ¬ A^T Aì˜ ì—­í–‰ë ¬ ê³„ì‚°
            # A^T A = [[Ix2, IxIy], [IxIy, Iy2]]
            # det(A^T A) = Ix2*Iy2 - IxIy^2
            det = Ix2 * Iy2 - IxIy * IxIy + 1e-6  # íŠ¹ì´ì  ë°©ì§€

            # (A^T A)^-1 = [[Iy2, -IxIy], [-IxIy, Ix2]] / det
            # [u; v] = -(A^T A)^-1 A^T b = -(A^T A)^-1 [IxIt; IyIt]
            u = -(Iy2 * IxIt - IxIy * IyIt) / det
            v = -(-IxIy * IxIt + Ix2 * IyIt) / det

            # Magnitude ê³„ì‚° (ì‹¤ì œ í”½ì…€ ë‹¨ìœ„ ì´ë™ ê±°ë¦¬)
            magnitude = torch.sqrt(u*u + v*v)
            motion_score = float(magnitude.mean().cpu().item())

            # GPU ë©”ëª¨ë¦¬ ì¦‰ì‹œ í•´ì œ
            del prev_tensor, curr_tensor, prev_gray, curr_gray
            del Ix, Iy, It, Ix2, Iy2, IxIy, IxIt, IyIt, det, u, v, magnitude

            return motion_score

        except Exception as e:
            # GPU ì˜¤ë¥˜ ì‹œ CPUë¡œ í´ë°±
            print(f"âš ï¸ GPU Flow ê³„ì‚° ì‹¤íŒ¨, CPUë¡œ ì „í™˜: {e}")
            self.gpu_available = False  # GPU ë¹„í™œì„±í™”

            prev_gray = cv2.cvtColor(prev_frame, cv2.COLOR_BGR2GRAY)
            curr_gray = cv2.cvtColor(current_frame, cv2.COLOR_BGR2GRAY)

            flow = cv2.calcOpticalFlowFarneback(
                prev_gray, curr_gray, None,
                pyr_scale=0.5, levels=3, winsize=15,
                iterations=3, poly_n=5, poly_sigma=1.2, flags=0
            )

            magnitude = np.sqrt(flow[..., 0]**2 + flow[..., 1]**2)
            motion_score = np.mean(magnitude)

            return motion_score

    def detect_segments(
        self,
        video_path: Path,
        progress_callback=None
    ) -> List[VideoSegment]:
        """
        ìƒˆë¡œìš´ ì›Œí¬í”Œë¡œìš°:
        1. ì •ì  êµ¬ê°„ ê°ì§€ (motion < threshold)
        2. ë™ì  êµ¬ê°„ ì¶”ì¶œ
        3. ë™ì  êµ¬ê°„ ë³‘í•©
        4. ê³ ì • ê¸¸ì´ë¡œ ë¶„í• 

        Args:
            video_path: ì…ë ¥ ë¹„ë””ì˜¤ ê²½ë¡œ
            progress_callback: ì§„í–‰ ìƒí™© ì½œë°± í•¨ìˆ˜(current, total)

        Returns:
            VideoSegment ë¦¬ìŠ¤íŠ¸ (ê³ ì • ê¸¸ì´ë¡œ ë¶„í• ëœ)
        """
        # Step 1: ë™ì  êµ¬ê°„ íƒì§€
        dynamic_ranges = self._detect_dynamic_ranges(video_path, progress_callback)

        if not dynamic_ranges:
            print("âš ï¸ ë™ì  êµ¬ê°„ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return []

        # Step 2: ë™ì  êµ¬ê°„ ë³‘í•© í›„ ê³ ì • ê¸¸ì´ë¡œ ë¶„í• 
        segments = self._merge_and_split_segments(dynamic_ranges)

        return segments

    def _detect_dynamic_ranges(
        self,
        video_path: Path,
        progress_callback=None
    ) -> List[DynamicRange]:
        """
        ì •ì  êµ¬ê°„ì„ ì œì™¸í•œ ë™ì  êµ¬ê°„ íƒ€ì„ìŠ¤íƒ¬í”„ ìˆ˜ì§‘

        Args:
            video_path: ì…ë ¥ ë¹„ë””ì˜¤ ê²½ë¡œ
            progress_callback: ì§„í–‰ ìƒí™© ì½œë°±

        Returns:
            DynamicRange ë¦¬ìŠ¤íŠ¸ (ì •ì  êµ¬ê°„ ì œì™¸)
        """
        # ë¹„ë””ì˜¤ ë¦¬ë” (OpenCV ë˜ëŠ” PyAV)
        cap = None
        using_pyav = False

        # 1ë‹¨ê³„: OpenCVë¡œ ì—´ê¸° ì‹œë„
        cap = cv2.VideoCapture(str(video_path))
        if not cap.isOpened():
            raise RuntimeError(f"ë¹„ë””ì˜¤ë¥¼ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {video_path}")

        fps = cap.get(cv2.CAP_PROP_FPS)
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        self.stats['total_frames'] = total_frames

        print(f"ğŸ“¹ ë¹„ë””ì˜¤ ë¶„ì„ ì¤‘...")
        print(f"   - FPS: {fps:.2f}")
        print(f"   - ì´ í”„ë ˆì„: {total_frames:,}ê°œ")
        print(f"   - ê¸¸ì´: {total_frames / fps / 60:.1f}ë¶„")
        print(f"   - Motion threshold: {self.config.motion_threshold:.2f}")
        if self.config.flow_scale < 1.0:
            print(f"   - Optical Flow í•´ìƒë„ ìŠ¤ì¼€ì¼: {self.config.flow_scale:.2f} (ì„±ëŠ¥ ìµœì í™” ì ìš©, ì¶œë ¥ì€ ì›ë³¸ ìœ ì§€)")
        if self.config.frame_skip > 1:
            print(f"   - í”„ë ˆì„ ìŠ¤í‚µ: {self.config.frame_skip} (ë¹ ë¥¸ ëª¨ë“œ, ~{self.config.frame_skip}ë°° ì†ë„ í–¥ìƒ)")

        # ì²« í”„ë ˆì„ ì½ê¸° ì‹œë„
        ret, prev_frame = cap.read()
        if not ret:
            # 2ë‹¨ê³„: OpenCV ì‹¤íŒ¨ ì‹œ PyAVë¡œ ì „í™˜
            print("âš ï¸ OpenCVë¡œ ì²« í”„ë ˆì„ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            print("   ë¹„ë””ì˜¤ ì½”ë±ì´ OpenCVì™€ í˜¸í™˜ë˜ì§€ ì•Šì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            print("ğŸ”„ PyAVë¡œ ì „í™˜ì„ ì‹œë„í•©ë‹ˆë‹¤...")
            print("   ğŸ’¡ ì•„ë˜ 'Failed to decode frame' ê²½ê³ ëŠ” PyAV ë‚´ë¶€ ë¡œê·¸ì´ë©° ë¬´ì‹œí•´ë„ ë©ë‹ˆë‹¤.")
            cap.release()

            # PyAVë¡œ ì—´ê¸°
            cap = PyAVVideoReader(video_path)
            if not cap.open():
                raise RuntimeError(
                    "ì²« í”„ë ˆì„ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n"
                    "ë¹„ë””ì˜¤ íŒŒì¼ì´ ì†ìƒë˜ì—ˆê±°ë‚˜ PyAVê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\n"
                    "PyAV ì„¤ì¹˜: pip install av"
                )

            # PyAVì—ì„œ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
            fps = cap.fps
            total_frames = cap.total_frames
            self.stats['total_frames'] = total_frames
            using_pyav = True

            # ì²« í”„ë ˆì„ ë‹¤ì‹œ ì½ê¸°
            ret, prev_frame = cap.read()
            if not ret:
                cap.release()
                raise RuntimeError("PyAVë¡œë„ ì²« í”„ë ˆì„ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")

        # ë™ì  êµ¬ê°„ ì¶”ì 
        dynamic_ranges = []
        current_range_start = None
        motion_buffer = []

        frame_idx = 0
        import time
        last_update_time = time.time()
        UPDATE_INTERVAL = 0.1

        while True:
            # í”„ë ˆì„ ìŠ¤í‚µ
            for _ in range(self.config.frame_skip - 1):
                ret = cap.grab()
                if not ret:
                    break
                frame_idx += 1

            ret, current_frame = cap.read()
            if not ret:
                break

            frame_idx += 1

            # ì§„í–‰ë¥  ì—…ë°ì´íŠ¸
            current_time = time.time()
            if progress_callback and (current_time - last_update_time >= UPDATE_INTERVAL):
                progress_callback(frame_idx, total_frames)
                last_update_time = current_time

            # Motion ê³„ì‚°
            motion_score = self.calculate_motion(prev_frame, current_frame)

            # ë™ì  í”„ë ˆì„ íŒì •
            is_dynamic = motion_score >= self.config.motion_threshold

            if is_dynamic:
                self.stats['dynamic_frames'] += 1
                motion_buffer.append(motion_score)

                # ìƒˆë¡œìš´ ë™ì  êµ¬ê°„ ì‹œì‘
                if current_range_start is None:
                    current_range_start = (frame_idx - 1) / fps  # ì‹œì‘ ì‹œê°„
            else:
                self.stats['static_frames'] += 1

                # ë™ì  êµ¬ê°„ ì¢…ë£Œ
                if current_range_start is not None and motion_buffer:
                    end_time = (frame_idx - 1) / fps
                    duration = end_time - current_range_start

                    # ìµœì†Œ ê¸¸ì´ ì²´í¬
                    if duration >= self.config.min_dynamic_duration:
                        avg_motion = sum(motion_buffer) / len(motion_buffer)
                        dynamic_ranges.append(DynamicRange(
                            start_time=current_range_start,
                            end_time=end_time,
                            duration=duration,
                            avg_motion=avg_motion
                        ))

                    # ë¦¬ì…‹
                    current_range_start = None
                    motion_buffer = []

            prev_frame = current_frame

        # ë§ˆì§€ë§‰ ë™ì  êµ¬ê°„ ì²˜ë¦¬
        if current_range_start is not None and motion_buffer:
            end_time = frame_idx / fps
            duration = end_time - current_range_start
            if duration >= self.config.min_dynamic_duration:
                avg_motion = sum(motion_buffer) / len(motion_buffer)
                dynamic_ranges.append(DynamicRange(
                    start_time=current_range_start,
                    end_time=end_time,
                    duration=duration,
                    avg_motion=avg_motion
                ))

        cap.release()

        # GPU ë©”ëª¨ë¦¬ ì •ë¦¬
        if self.gpu_available and self.device and self.device.type == 'cuda':
            try:
                import torch
                torch.cuda.empty_cache()
                torch.cuda.synchronize()
            except:
                pass

        self.stats['dynamic_ranges'] = len(dynamic_ranges)
        total_dynamic_duration = sum(r.duration for r in dynamic_ranges)

        print(f"\nâœ… ë™ì  êµ¬ê°„ íƒì§€ ì™„ë£Œ!")
        print(f"   - ë™ì  í”„ë ˆì„: {self.stats['dynamic_frames']:,}ê°œ")
        print(f"   - ì •ì  í”„ë ˆì„: {self.stats['static_frames']:,}ê°œ")
        print(f"   - ë™ì  êµ¬ê°„: {len(dynamic_ranges)}ê°œ (ì´ {total_dynamic_duration:.1f}ì´ˆ)")

        return dynamic_ranges

    def _merge_and_split_segments(
        self,
        dynamic_ranges: List[DynamicRange]
    ) -> List[VideoSegment]:
        """
        ë™ì  êµ¬ê°„ë“¤ì„ ë³‘í•©í•œ í›„ ê³ ì • ê¸¸ì´ë¡œ ë¶„í• 

        Args:
            dynamic_ranges: ë™ì  êµ¬ê°„ ë¦¬ìŠ¤íŠ¸

        Returns:
            VideoSegment ë¦¬ìŠ¤íŠ¸ (target_duration ê¸¸ì´ë¡œ ë¶„í• )
        """
        if not dynamic_ranges:
            return []

        # ì „ì²´ ë™ì  êµ¬ê°„ ê¸¸ì´ ê³„ì‚°
        total_dynamic_duration = sum(r.duration for r in dynamic_ranges)

        print(f"\nğŸ”€ ë™ì  êµ¬ê°„ ë³‘í•© ë° ë¶„í•  ì¤‘...")
        print(f"   - ë³‘í•©ëœ ë™ì  êµ¬ê°„ ì´ ê¸¸ì´: {total_dynamic_duration:.1f}ì´ˆ")
        print(f"   - ëª©í‘œ í´ë¦½ ê¸¸ì´: {self.config.target_duration:.1f}ì´ˆ")

        segments = []
        accumulated_time = 0.0
        segment_start = 0.0
        current_segment_ranges = []  # í˜„ì¬ ì„¸ê·¸ë¨¼íŠ¸ì— í¬í•¨ëœ ë™ì  êµ¬ê°„ë“¤

        for dyn_range in dynamic_ranges:
            current_segment_ranges.append(dyn_range)
            accumulated_time += dyn_range.duration

            # target_duration ë„ë‹¬ ì‹œ ì„¸ê·¸ë¨¼íŠ¸ ìƒì„±
            if accumulated_time >= self.config.target_duration:
                # í‰ê·  motion ê³„ì‚°
                total_motion = sum(r.avg_motion * r.duration for r in current_segment_ranges)
                total_dur = sum(r.duration for r in current_segment_ranges)
                avg_motion = total_motion / total_dur if total_dur > 0 else 0.0

                segments.append(VideoSegment(
                    start_time=segment_start,
                    end_time=segment_start + accumulated_time,
                    duration=accumulated_time,
                    avg_motion=avg_motion
                ))

                # ë‹¤ìŒ ì„¸ê·¸ë¨¼íŠ¸ ì¤€ë¹„
                segment_start += accumulated_time
                accumulated_time = 0.0
                current_segment_ranges = []

        # ë§ˆì§€ë§‰ ë‚¨ì€ êµ¬ê°„ ì²˜ë¦¬
        if accumulated_time > 0 and current_segment_ranges:
            total_motion = sum(r.avg_motion * r.duration for r in current_segment_ranges)
            total_dur = sum(r.duration for r in current_segment_ranges)
            avg_motion = total_motion / total_dur if total_dur > 0 else 0.0

            segments.append(VideoSegment(
                start_time=segment_start,
                end_time=segment_start + accumulated_time,
                duration=accumulated_time,
                avg_motion=avg_motion
            ))

        self.stats['final_segments'] = len(segments)

        print(f"   âœ… ìµœì¢… ì„¸ê·¸ë¨¼íŠ¸: {len(segments)}ê°œ")
        for i, seg in enumerate(segments, 1):
            print(f"      #{i}: {seg.duration:.1f}ì´ˆ (Motion: {seg.avg_motion:.2f})")

        return segments


    def export_segments(
        self,
        video_path: Path,
        segments: List[VideoSegment],
        output_dir: Path,
        progress_callback=None
    ) -> List[Path]:
        """
        ì„¸ê·¸ë¨¼íŠ¸ë¥¼ ê°œë³„ ë¹„ë””ì˜¤ íŒŒì¼ë¡œ ì €ì¥ (ffmpeg ì‚¬ìš©)

        Args:
            video_path: ì›ë³¸ ë¹„ë””ì˜¤ ê²½ë¡œ
            segments: ì„¸ê·¸ë¨¼íŠ¸ ë¦¬ìŠ¤íŠ¸
            output_dir: ì¶œë ¥ ë””ë ‰í† ë¦¬
            progress_callback: ì§„í–‰ ìƒí™© ì½œë°±

        Returns:
            ì €ì¥ëœ ë¹„ë””ì˜¤ íŒŒì¼ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸
        """
        # ffmpeg í™•ì¸ ë° ìë™ ì„¤ì¹˜
        if not check_and_install_ffmpeg():
            raise RuntimeError(
                "ffmpegë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. "
                "í„°ë¯¸ë„ì„ ì¬ì‹œì‘í•˜ê±°ë‚˜ ìˆ˜ë™ìœ¼ë¡œ ì„¤ì¹˜í•´ì£¼ì„¸ìš”."
            )

        output_dir.mkdir(parents=True, exist_ok=True)

        saved_paths = []

        print(f"\nğŸ¬ ì„¸ê·¸ë¨¼íŠ¸ ë¹„ë””ì˜¤ ìƒì„± ì¤‘ (ffmpeg)...")

        for idx, segment in enumerate(segments):
            output_path = output_dir / f"segment_{idx+1:03d}.mp4"

            # ffmpegë¡œ ë¹„ë””ì˜¤ ìë¥´ê¸° (ì¬ì¸ì½”ë”© ì—†ì´ ë¹ ë¥´ê²Œ)
            cmd = [
                'ffmpeg',
                '-i', str(video_path),
                '-ss', str(segment.start_time),
                '-to', str(segment.end_time),
                '-c', 'copy',
                '-y',  # ë®ì–´ì“°ê¸°
                str(output_path)
            ]

            try:
                subprocess.run(
                    cmd,
                    check=True,
                    capture_output=True,
                    text=True,
                    creationflags=subprocess.CREATE_NO_WINDOW if os.name == 'nt' else 0
                )
                saved_paths.append(output_path)

                if progress_callback:
                    progress_callback(idx + 1, len(segments))

                print(f"   âœ“ segment_{idx+1:03d}.mp4 ({segment.duration:.1f}ì´ˆ, "
                      f"Motion: {segment.avg_motion:.2f})")
            except subprocess.CalledProcessError as e:
                print(f"   âš ï¸ segment_{idx+1:03d}.mp4 ìƒì„± ì‹¤íŒ¨: {e.stderr}")

        # GPU ë©”ëª¨ë¦¬ ì •ë¦¬ (GPU ê°€ì† ì‚¬ìš© ì‹œ)
        if self.gpu_available and self.device and self.device.type == 'cuda':
            try:
                import torch
                torch.cuda.empty_cache()
                torch.cuda.synchronize()
            except:
                pass

        print(f"\nâœ… {len(saved_paths)}ê°œ ì„¸ê·¸ë¨¼íŠ¸ ì €ì¥ ì™„ë£Œ!")
        return saved_paths

    def save_metadata(
        self,
        output_dir: Path,
        video_path: Path,
        segments: List[VideoSegment]
    ):
        """ë©”íƒ€ë°ì´í„° ì €ì¥"""
        metadata = {
            'source_video': str(video_path),
            'timestamp': datetime.now().isoformat(),
            'config': {
                'motion_threshold': self.config.motion_threshold,
                'target_duration': self.config.target_duration,
                'min_dynamic_duration': self.config.min_dynamic_duration,
                'batch_size': self.config.batch_size,
                'flow_scale': self.config.flow_scale,
                'frame_skip': self.config.frame_skip,
                'use_gpu': self.config.use_gpu,
            },
            'stats': self.stats,
            'segments': [
                {
                    'index': i + 1,
                    'filename': f"segment_{i+1:03d}.mp4",
                    'start_time': seg.start_time,
                    'end_time': seg.end_time,
                    'duration': seg.duration,
                    'avg_motion': seg.avg_motion,
                }
                for i, seg in enumerate(segments)
            ]
        }

        metadata_path = output_dir / "segments_metadata.json"
        with open(metadata_path, 'w', encoding='utf-8') as f:
            json.dump(metadata, f, ensure_ascii=False, indent=2)

        print(f"\nğŸ’¾ ë©”íƒ€ë°ì´í„° ì €ì¥: {metadata_path}")

    def _print_stats(self):
        """í†µê³„ ì¶œë ¥"""
        print(f"\nğŸ“Š ì„¸ê·¸ë©˜í…Œì´ì…˜ í†µê³„:")
        print(f"   - ì´ í”„ë ˆì„: {self.stats['total_frames']:,}ê°œ")
        print(f"   - ë™ì  í”„ë ˆì„: {self.stats['dynamic_frames']:,}ê°œ")
        print(f"   - ì •ì  í”„ë ˆì„: {self.stats['static_frames']:,}ê°œ")
        print(f"   - ë™ì  êµ¬ê°„ ìˆ˜: {self.stats['dynamic_ranges']:,}ê°œ")
        print(f"   - ìµœì¢… ì„¸ê·¸ë¨¼íŠ¸: {self.stats['final_segments']:,}ê°œ")

        # Optical Flow ì„±ëŠ¥ í†µê³„
        gpu_count = self.stats['flow_gpu_count']
        cpu_count = self.stats['flow_cpu_count']
        gpu_time = self.stats['flow_gpu_time']
        cpu_time = self.stats['flow_cpu_time']

        if gpu_count > 0 or cpu_count > 0:
            print(f"\nâš¡ Optical Flow ì„±ëŠ¥ í†µê³„:")
            if gpu_count > 0:
                avg_gpu_time = (gpu_time / gpu_count) * 1000  # ms
                print(f"   - GPU Flow: {gpu_count:,}íšŒ, í‰ê·  {avg_gpu_time:.2f}ms/í”„ë ˆì„, ì´ {gpu_time:.2f}ì´ˆ")
            if cpu_count > 0:
                avg_cpu_time = (cpu_time / cpu_count) * 1000  # ms
                print(f"   - CPU Flow: {cpu_count:,}íšŒ, í‰ê·  {avg_cpu_time:.2f}ms/í”„ë ˆì„, ì´ {cpu_time:.2f}ì´ˆ")
            if gpu_count > 0 and cpu_count > 0:
                speedup = (cpu_time / cpu_count) / (gpu_time / gpu_count)
                print(f"   - GPU ê°€ì† ë°°ìœ¨: {speedup:.1f}x")


def main():
    parser = argparse.ArgumentParser(
        description="Optical Flow ê¸°ë°˜ ìŠ¤ë§ˆíŠ¸ ë¹„ë””ì˜¤ ì„¸ê·¸ë©˜í…Œì´ì…˜"
    )
    parser.add_argument(
        '--input',
        type=Path,
        required=True,
        help="ì…ë ¥ ë¹„ë””ì˜¤ ê²½ë¡œ"
    )
    parser.add_argument(
        '--output',
        type=Path,
        required=True,
        help="ì¶œë ¥ ë””ë ‰í† ë¦¬"
    )
    parser.add_argument(
        '--motion-low',
        type=float,
        default=2.0,
        help="ì €ë™ì  êµ¬ê°„ ì„ê³„ê°’ - ì´ë³´ë‹¤ ë‚®ìœ¼ë©´ ì œì™¸ (ê¸°ë³¸: 2.0)"
    )
    parser.add_argument(
        '--motion-high',
        type=float,
        default=15.0,
        help="ê³ ë™ì  êµ¬ê°„ ì„ê³„ê°’ - ì´ë³´ë‹¤ ë†’ìœ¼ë©´ ê³¼ë„í•œ ì›€ì§ì„ìœ¼ë¡œ ì œì™¸ (ê¸°ë³¸: 15.0)"
    )
    parser.add_argument(
        '--scene-threshold',
        type=float,
        default=0.5,
        help="ì¥ë©´ ì „í™˜ ì„ê³„ê°’ (íˆìŠ¤í† ê·¸ë¨ ì°¨ì´, ê¸°ë³¸: 0.5)"
    )
    parser.add_argument(
        '--min-duration',
        type=float,
        default=5.0,
        help="ìµœì†Œ ì„¸ê·¸ë¨¼íŠ¸ ê¸¸ì´ ì´ˆ (ê¸°ë³¸: 5.0)"
    )
    parser.add_argument(
        '--max-duration',
        type=float,
        default=60.0,
        help="ìµœëŒ€ ì„¸ê·¸ë¨¼íŠ¸ ê¸¸ì´ ì´ˆ (ê¸°ë³¸: 60.0)"
    )
    parser.add_argument(
        '--max-segments',
        type=int,
        default=None,
        help="ìµœëŒ€ ì„¸ê·¸ë¨¼íŠ¸ ìˆ˜ (ê¸°ë³¸: ë¬´ì œí•œ)"
    )
    parser.add_argument(
        '--flow-scale',
        type=float,
        default=0.5,
        help="Optical Flow ê³„ì‚° ì‹œ í•´ìƒë„ ìŠ¤ì¼€ì¼ (0.5=2ë°° ë¹ ë¦„, 1.0=ì›ë³¸, ê¸°ë³¸: 0.5)"
    )
    parser.add_argument(
        '--frame-skip',
        type=int,
        default=1,
        help="í”„ë ˆì„ ìŠ¤í‚µ (1=ëª¨ë“  í”„ë ˆì„, 3=3í”„ë ˆì„ë§ˆë‹¤, ê¸°ë³¸: 1)"
    )
    parser.add_argument(
        '--save-discarded',
        action='store_true',
        help="ì±„íƒë˜ì§€ ì•Šì€ êµ¬ê°„ë„ else í´ë”ì— ì €ì¥ (ì‹¤í—˜ ê¸°ëŠ¥)"
    )
    parser.add_argument(
        '--use-gpu',
        action='store_true',
        help="GPU ê°€ì† ì‚¬ìš© (CUDA ì‚¬ìš© ê°€ëŠ¥ ì‹œ)"
    )

    args = parser.parse_args()

    # ì„¤ì • ìƒì„±
    config = SegmentConfig(
        motion_low_threshold=args.motion_low,
        motion_high_threshold=args.motion_high,
        scene_change_threshold=args.scene_threshold,
        scene_change_important=args.scene_threshold,
        min_duration=args.min_duration,
        max_duration=args.max_duration,
        max_segments=args.max_segments,
        flow_scale=args.flow_scale,
        frame_skip=args.frame_skip,
        save_discarded=args.save_discarded,
        use_gpu=args.use_gpu
    )

    # ì„¸ê·¸ë©˜í„° ìƒì„±
    segmenter = VideoSegmenter(config)

    # ì§„í–‰ ìƒí™© ì½œë°±
    def progress_callback(current, total):
        print(f"   ì§„í–‰: {current:,} / {total:,} ({current / total * 100:.1f}%)", end='\r')

    try:
        # ì„¸ê·¸ë¨¼íŠ¸ íƒì§€
        segments = segmenter.detect_segments(args.input, progress_callback)

        if not segments:
            print("\nâŒ ìœ íš¨í•œ ì„¸ê·¸ë¨¼íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return 1

        # ì„¸ê·¸ë¨¼íŠ¸ ë¹„ë””ì˜¤ ìƒì„±
        saved_paths = segmenter.export_segments(
            args.input,
            segments,
            args.output,
            progress_callback
        )

        # ë©”íƒ€ë°ì´í„° ì €ì¥
        segmenter.save_metadata(args.output, args.input, segments)

        print(f"\nâœ… ì™„ë£Œ!")
        print(f"   ì¶œë ¥ ë””ë ‰í† ë¦¬: {args.output}")
        print(f"   ì„¸ê·¸ë¨¼íŠ¸ ìˆ˜: {len(saved_paths)}ê°œ")

        total_duration = sum(seg.duration for seg in segments)
        print(f"   ì´ ê¸¸ì´: {total_duration / 60:.1f}ë¶„")

    except Exception as e:
        print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
        return 1

    return 0


if __name__ == '__main__':
    exit(main())
