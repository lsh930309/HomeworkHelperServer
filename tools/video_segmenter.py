#!/usr/bin/env python3
"""
SSIM ê¸°ë°˜ ìŠ¤ë§ˆíŠ¸ ë¹„ë””ì˜¤ ì„¸ê·¸ë©˜í…Œì´ì…˜
ë¹„ë””ì˜¤ë¥¼ ë™ì  ë°°ê²½ êµ¬ê°„ìœ¼ë¡œ ë¶„í• í•˜ì—¬ YOLO ê³¼ì í•© ë°©ì§€ ë° ë¼ë²¨ë§ íš¨ìœ¨ ê·¹ëŒ€í™”
UIëŠ” ê³ ì •ë˜ê³  ë°°ê²½ë§Œ ë³€í•˜ëŠ” êµ¬ê°„ ì„ íƒ

ì‚¬ìš©ë²•:
    python tools/video_segmenter.py --input datasets/raw/gameplay.mp4 \
                                     --output datasets/clips/ \
                                     --dynamic-low 0.4 \
                                     --dynamic-high 0.8 \
                                     --min-duration 5
"""

import argparse
import cv2
import numpy as np
from pathlib import Path
from typing import List, Tuple, Optional
from dataclasses import dataclass
import json
from datetime import datetime
from skimage.metrics import structural_similarity as ssim
import subprocess
import shutil
import sys


def refresh_system_path():
    """
    ì‹œìŠ¤í…œ PATH í™˜ê²½ë³€ìˆ˜ë¥¼ ë ˆì§€ìŠ¤íŠ¸ë¦¬ì—ì„œ ìƒˆë¡œê³ ì¹¨ (Windows ì „ìš©)
    winget ì„¤ì¹˜ í›„ í˜„ì¬ í”„ë¡œì„¸ìŠ¤ì—ì„œ PATHë¥¼ ì¦‰ì‹œ ì‚¬ìš©í•˜ê¸° ìœ„í•¨
    """
    if sys.platform != 'win32':
        return

    try:
        import winreg
        import os

        # ì‹œìŠ¤í…œ PATH ì½ê¸°
        with winreg.OpenKey(winreg.HKEY_LOCAL_MACHINE,
                           r'SYSTEM\CurrentControlSet\Control\Session Manager\Environment',
                           0, winreg.KEY_READ) as key:
            system_path, _ = winreg.QueryValueEx(key, 'Path')

        # ì‚¬ìš©ì PATH ì½ê¸°
        with winreg.OpenKey(winreg.HKEY_CURRENT_USER,
                           r'Environment',
                           0, winreg.KEY_READ) as key:
            try:
                user_path, _ = winreg.QueryValueEx(key, 'Path')
            except FileNotFoundError:
                user_path = ''

        # í˜„ì¬ í”„ë¡œì„¸ìŠ¤ì˜ PATH ì—…ë°ì´íŠ¸
        combined_path = f"{user_path};{system_path}" if user_path else system_path
        os.environ['PATH'] = combined_path

    except Exception as e:
        # PATH ìƒˆë¡œê³ ì¹¨ ì‹¤íŒ¨ëŠ” ì¹˜ëª…ì ì´ì§€ ì•Šìœ¼ë¯€ë¡œ ë¬´ì‹œ
        pass


def check_and_install_ffmpeg() -> bool:
    """
    ffmpeg ì„¤ì¹˜ ì—¬ë¶€ í™•ì¸ ë° ìë™ ì„¤ì¹˜

    Returns:
        bool: ffmpegê°€ ì‚¬ìš© ê°€ëŠ¥í•˜ë©´ True, ì„¤ì¹˜ ì‹¤íŒ¨í•˜ë©´ False
    """
    # ffmpegê°€ ì´ë¯¸ PATHì— ìˆëŠ”ì§€ í™•ì¸
    if shutil.which('ffmpeg') is not None:
        return True

    print("âš ï¸ ffmpegë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    print("ğŸ”§ ffmpegë¥¼ ìë™ìœ¼ë¡œ ì„¤ì¹˜í•©ë‹ˆë‹¤ (winget ì‚¬ìš©)...")

    try:
        # wingetìœ¼ë¡œ ffmpeg ì„¤ì¹˜ ì‹œë„
        result = subprocess.run(
            ['winget', 'install', 'Gyan.FFmpeg', '--accept-source-agreements', '--accept-package-agreements'],
            capture_output=True,
            text=True,
            timeout=300  # 5ë¶„ íƒ€ì„ì•„ì›ƒ
        )

        if result.returncode == 0:
            print("âœ… ffmpeg ì„¤ì¹˜ ì™„ë£Œ!")

            # PATH ìƒˆë¡œê³ ì¹¨ ì‹œë„
            print("ğŸ”„ PATH í™˜ê²½ë³€ìˆ˜ ìƒˆë¡œê³ ì¹¨ ì¤‘...")
            refresh_system_path()

            # ì„¤ì¹˜ í›„ ë‹¤ì‹œ í™•ì¸
            if shutil.which('ffmpeg') is not None:
                print("âœ… ffmpegë¥¼ ë°”ë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤!")
                return True
            else:
                print("   âš ï¸ ì„¤ì¹˜ëŠ” ì™„ë£Œë˜ì—ˆìœ¼ë‚˜ PATHì—ì„œ ffmpegë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                print("   â„¹ï¸ ë‹¤ìŒ ì¤‘ í•˜ë‚˜ë¥¼ ì‹œë„í•´ì£¼ì„¸ìš”:")
                print("      1. í„°ë¯¸ë„ì„ ì¬ì‹œì‘í•œ í›„ ë‹¤ì‹œ ì‹¤í–‰")
                print("      2. ì‹œìŠ¤í…œì„ ì¬ë¶€íŒ…")
                return False
        else:
            print(f"âŒ ffmpeg ì„¤ì¹˜ ì‹¤íŒ¨")
            if result.stderr:
                print(f"   ì˜¤ë¥˜ ë©”ì‹œì§€: {result.stderr[:200]}")
            print("   â„¹ï¸ ìˆ˜ë™ ì„¤ì¹˜ ë°©ë²•:")
            print("      1. í„°ë¯¸ë„ì—ì„œ 'winget install Gyan.FFmpeg' ì‹¤í–‰")
            print("      2. ë˜ëŠ” https://www.gyan.dev/ffmpeg/builds/ ì—ì„œ ë‹¤ìš´ë¡œë“œ")
            return False

    except FileNotFoundError:
        print("âŒ wingetì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        print("   â„¹ï¸ Windows 10 1809 ì´ìƒ ë˜ëŠ” Windows 11ì´ í•„ìš”í•©ë‹ˆë‹¤.")
        print("   â„¹ï¸ ìˆ˜ë™ ì„¤ì¹˜: https://www.gyan.dev/ffmpeg/builds/")
        return False
    except subprocess.TimeoutExpired:
        print("âŒ ffmpeg ì„¤ì¹˜ ì‹œê°„ ì´ˆê³¼ (5ë¶„)")
        print("   â„¹ï¸ ë„¤íŠ¸ì›Œí¬ ìƒíƒœë¥¼ í™•ì¸í•˜ê³  ìˆ˜ë™ìœ¼ë¡œ ì„¤ì¹˜í•´ì£¼ì„¸ìš”.")
        return False
    except Exception as e:
        print(f"âŒ ffmpeg ì„¤ì¹˜ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}")
        return False


class PyAVVideoReader:
    """
    PyAVë¥¼ ì‚¬ìš©í•œ ë¹„ë””ì˜¤ ë¦¬ë” (OpenCVê°€ ì§€ì›í•˜ì§€ ì•ŠëŠ” ì½”ë± ì²˜ë¦¬)
    AV1, H.265, VP9 ë“± ëª¨ë“  FFmpeg ì§€ì› ì½”ë±ì„ ë¬´ì†ì‹¤ë¡œ ì½ì„ ìˆ˜ ìˆìŒ
    """

    def __init__(self, video_path: Path):
        """
        Args:
            video_path: ë¹„ë””ì˜¤ íŒŒì¼ ê²½ë¡œ
        """
        self.video_path = video_path
        self.container = None
        self.video_stream = None
        self.fps = None
        self.total_frames = None
        self.width = None
        self.height = None
        self._frame_generator = None

    def open(self) -> bool:
        """
        ë¹„ë””ì˜¤ íŒŒì¼ ì—´ê¸°

        Returns:
            bool: ì„±ê³µ ì—¬ë¶€
        """
        try:
            import av

            self.container = av.open(str(self.video_path))
            self.video_stream = self.container.streams.video[0]

            # ë¹„ë””ì˜¤ ì •ë³´ ì¶”ì¶œ
            self.fps = float(self.video_stream.average_rate)
            self.total_frames = self.video_stream.frames
            self.width = self.video_stream.width
            self.height = self.video_stream.height

            # total_framesê°€ 0ì´ë©´ durationìœ¼ë¡œ ì¶”ì •
            if self.total_frames == 0 and self.container.duration:
                self.total_frames = int(self.container.duration * self.fps / av.time_base)

            # í”„ë ˆì„ ì œë„ˆë ˆì´í„° ì´ˆê¸°í™”
            self._frame_generator = self.container.decode(video=0)

            print(f"âœ… PyAVë¡œ ë¹„ë””ì˜¤ ì—´ê¸° ì„±ê³µ")
            print(f"   ì½”ë±: {self.video_stream.codec_context.name}")

            return True

        except ImportError:
            print("âš ï¸ PyAVê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            print("   ì„¤ì¹˜ ë°©ë²•: pip install av")
            return False
        except Exception as e:
            print(f"âš ï¸ PyAVë¡œ ë¹„ë””ì˜¤ ì—´ê¸° ì‹¤íŒ¨: {e}")
            return False

    def read(self):
        """
        ë‹¤ìŒ í”„ë ˆì„ ì½ê¸° (OpenCVì˜ cap.read()ì™€ ë™ì¼í•œ ì¸í„°í˜ì´ìŠ¤)

        Returns:
            tuple: (success, frame_bgr) - OpenCV í˜•ì‹ì˜ BGR numpy array
        """
        try:
            frame = next(self._frame_generator)
            # BGR í¬ë§·ìœ¼ë¡œ ë³€í™˜ (OpenCV í˜¸í™˜)
            img = frame.to_ndarray(format='bgr24')
            return True, img
        except StopIteration:
            return False, None
        except Exception as e:
            return False, None

    def grab(self):
        """
        í”„ë ˆì„ì„ ê±´ë„ˆë›°ê¸° (OpenCVì˜ cap.grab()ì™€ ë™ì¼í•œ ì¸í„°í˜ì´ìŠ¤)
        PyAVëŠ” grabì„ ì§ì ‘ ì§€ì›í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ readí•˜ê³  ë²„ë¦¼

        Returns:
            bool: ì„±ê³µ ì—¬ë¶€
        """
        try:
            frame = next(self._frame_generator)
            return True
        except StopIteration:
            return False
        except Exception as e:
            return False

    def release(self):
        """ë¦¬ì†ŒìŠ¤ í•´ì œ"""
        if self.container:
            self.container.close()
            self.container = None

    def isOpened(self) -> bool:
        """ë¹„ë””ì˜¤ê°€ ì—´ë ¤ìˆëŠ”ì§€ í™•ì¸"""
        return self.container is not None


def _process_chunk_worker(chunk_info, video_path, config, fps):
    """
    ë©€í‹°í”„ë¡œì„¸ì‹± ì›Œì»¤ í•¨ìˆ˜: ì²­í¬ë¥¼ ì²˜ë¦¬í•˜ì—¬ ì„¸ê·¸ë¨¼íŠ¸ íƒì§€

    Args:
        chunk_info: (start_frame, end_frame) íŠœí”Œ
        video_path: ë¹„ë””ì˜¤ íŒŒì¼ ê²½ë¡œ
        config: SegmentConfig
        fps: ë¹„ë””ì˜¤ FPS

    Returns:
        ì„¸ê·¸ë¨¼íŠ¸ ë¦¬ìŠ¤íŠ¸
    """
    start_frame, end_frame = chunk_info

    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        return []

    cap.set(cv2.CAP_PROP_POS_FRAMES, start_frame)

    segments = []
    current_segment_start = start_frame
    dynamic_frame_count = 0
    ssim_buffer = []

    ret, prev_frame = cap.read()
    if not ret:
        cap.release()
        return []

    frame_idx = start_frame

    while frame_idx < end_frame:
        # í”„ë ˆì„ ìŠ¤í‚µ ì ìš©
        for _ in range(config.frame_skip - 1):
            ret = cap.grab()
            if not ret:
                break
            frame_idx += 1

        ret, current_frame = cap.read()
        if not ret:
            break

        frame_idx += 1

        # SSIM ê³„ì‚°
        ssim_score = _calculate_ssim_for_worker(prev_frame, current_frame, config.ssim_scale)
        ssim_buffer.append(ssim_score)

        # ì¥ë©´ ì „í™˜ ê°ì§€
        if ssim_score < config.scene_change_threshold:
            # ì´ì „ ì„¸ê·¸ë¨¼íŠ¸ ì €ì¥ (ì¡°ê±´ ì¶©ì¡± ì‹œ)
            if dynamic_frame_count >= config.min_dynamic_frames:
                segment = _create_segment_for_worker(
                    current_segment_start,
                    frame_idx - 1,
                    fps,
                    ssim_buffer[:-1],
                    config
                )

                if segment:
                    segments.append(segment)

            # ìƒˆ ì„¸ê·¸ë¨¼íŠ¸ ì‹œì‘
            current_segment_start = frame_idx
            dynamic_frame_count = 0
            ssim_buffer = []

        # ë™ì  êµ¬ê°„ ì¹´ìš´íŠ¸
        elif (config.dynamic_low_threshold <= ssim_score <= config.dynamic_high_threshold):
            dynamic_frame_count += 1

        prev_frame = current_frame

    # ë§ˆì§€ë§‰ ì„¸ê·¸ë¨¼íŠ¸ ì²˜ë¦¬
    if dynamic_frame_count >= config.min_dynamic_frames:
        segment = _create_segment_for_worker(
            current_segment_start,
            frame_idx,
            fps,
            ssim_buffer,
            config
        )

        if segment:
            segments.append(segment)

    cap.release()
    return segments


def _calculate_ssim_for_worker(img1, img2, ssim_scale):
    """ì›Œì»¤ìš© SSIM ê³„ì‚°"""
    # í•´ìƒë„ ì¶•ì†Œ
    if ssim_scale < 1.0:
        h, w = img1.shape[:2]
        new_h = int(h * ssim_scale)
        new_w = int(w * ssim_scale)
        img1 = cv2.resize(img1, (new_w, new_h), interpolation=cv2.INTER_AREA)
        img2 = cv2.resize(img2, (new_w, new_h), interpolation=cv2.INTER_AREA)

    gray1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)
    gray2 = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)
    score, _ = ssim(gray1, gray2, full=True)
    return score


def _create_segment_for_worker(start_frame, end_frame, fps, ssim_scores, config):
    """ì›Œì»¤ìš© ì„¸ê·¸ë¨¼íŠ¸ ìƒì„± ë° ê²€ì¦"""
    start_time = start_frame / fps
    end_time = end_frame / fps
    duration = end_time - start_time
    avg_ssim = np.mean(ssim_scores) if ssim_scores else 0.0

    # ìµœì†Œ ê¸¸ì´ ì²´í¬
    if duration < config.min_duration:
        return None

    # ë™ì  ë²”ìœ„ ì²´í¬
    if not (config.dynamic_low_threshold <= avg_ssim <= config.dynamic_high_threshold):
        return None

    return VideoSegment(
        start_frame=start_frame,
        end_frame=end_frame,
        start_time=start_time,
        end_time=end_time,
        duration=duration,
        avg_ssim=avg_ssim
    )


@dataclass
class VideoSegment:
    """ë¹„ë””ì˜¤ ì„¸ê·¸ë¨¼íŠ¸ ì •ë³´"""
    start_frame: int
    end_frame: int
    start_time: float
    end_time: float
    duration: float
    avg_ssim: float  # êµ¬ê°„ ë‚´ í‰ê·  SSIM (ì•ˆì •ì„± ì§€í‘œ)


@dataclass
class SegmentConfig:
    """ì„¸ê·¸ë©˜í…Œì´ì…˜ ì„¤ì •"""
    # ì¥ë©´ ì „í™˜ ê°ì§€ (ë„ˆë¬´ ë‚®ì€ SSIM)
    scene_change_threshold: float = 0.3  # SSIMì´ ì´ë³´ë‹¤ ë‚®ìœ¼ë©´ ì¥ë©´ ì „í™˜ (ì œì™¸)

    # ë™ì  êµ¬ê°„ ê°ì§€ (ì ì ˆí•œ ë°°ê²½ ë³€í™”)
    dynamic_low_threshold: float = 0.4    # SSIM ìµœì†Œê°’ (ì´ë³´ë‹¤ ë‚®ìœ¼ë©´ ë„ˆë¬´ ë™ì )
    dynamic_high_threshold: float = 0.8   # SSIM ìµœëŒ€ê°’ (ì´ë³´ë‹¤ ë†’ìœ¼ë©´ ë„ˆë¬´ ì •ì )
    min_dynamic_frames: int = 30          # ìµœì†Œ ë™ì  í”„ë ˆì„ ìˆ˜ (1ì´ˆ@30fps)

    # ì„¸ê·¸ë¨¼íŠ¸ ì œì•½
    min_duration: float = 5.0            # ìµœì†Œ ì„¸ê·¸ë¨¼íŠ¸ ê¸¸ì´ (ì´ˆ)
    max_duration: float = 60.0           # ìµœëŒ€ ì„¸ê·¸ë¨¼íŠ¸ ê¸¸ì´ (ì´ˆ)
    max_segments: Optional[int] = None   # ìµœëŒ€ ì„¸ê·¸ë¨¼íŠ¸ ìˆ˜

    # ì„±ëŠ¥ ìµœì í™”
    ssim_scale: float = 1.0              # SSIM ê³„ì‚° ì‹œ í•´ìƒë„ ìŠ¤ì¼€ì¼ (0.25 = 4ë°° ë¹ ë¦„, ì¶œë ¥ì€ ì›ë³¸ ìœ ì§€)
    frame_skip: int = 1                  # í”„ë ˆì„ ìŠ¤í‚µ (1=ëª¨ë“  í”„ë ˆì„, 3=3í”„ë ˆì„ë§ˆë‹¤)
    use_multiprocessing: bool = True     # ë©€í‹°í”„ë¡œì„¸ì‹± ì‚¬ìš© (8ì½”ì–´ ê¸°ì¤€ 4-8ë°° ë¹ ë¦„)
    num_workers: Optional[int] = None    # ì›Œì»¤ ìˆ˜ (Noneì´ë©´ CPU ì½”ì–´ ìˆ˜)

    # ì‹¤í—˜ ê¸°ëŠ¥
    save_discarded: bool = False         # ì±„íƒë˜ì§€ ì•Šì€ êµ¬ê°„ë„ ë³„ë„ ì €ì¥

    # ì¶œë ¥ ì„¤ì •
    output_codec: str = "mp4v"           # ì¶œë ¥ ì½”ë±
    output_fps: Optional[int] = None     # ì¶œë ¥ FPS (Noneì´ë©´ ì›ë³¸)


class VideoSegmenter:
    """SSIM ê¸°ë°˜ ë¹„ë””ì˜¤ ì„¸ê·¸ë©˜í…Œì´ì…˜"""

    def __init__(self, config: SegmentConfig = None):
        self.config = config or SegmentConfig()
        self.stats = {
            'total_frames': 0,
            'scene_changes': 0,
            'dynamic_segments': 0,
            'discarded_short': 0,
            'discarded_static': 0,
            'discarded_chaotic': 0
        }

    def _calculate_optimal_workers(self, video_duration_minutes: float) -> int:
        """
        ì‹œìŠ¤í…œ ì‚¬ì–‘ê³¼ ë¹„ë””ì˜¤ íŠ¹ì„±ì„ ê³ ë ¤í•œ ìµœì  ì›Œì»¤ ìˆ˜ ê³„ì‚°

        Args:
            video_duration_minutes: ë¹„ë””ì˜¤ ê¸¸ì´ (ë¶„)

        Returns:
            ìµœì  ì›Œì»¤ ìˆ˜
        """
        import multiprocessing as mp

        # 1. ë…¼ë¦¬ ì½”ì–´ ìˆ˜ (í•˜ì´í¼ìŠ¤ë ˆë”© í¬í•¨)
        logical_cores = mp.cpu_count()

        # 2. ë¬¼ë¦¬ ì½”ì–´ ìˆ˜ ì¶”ì • (psutil ì—†ì´)
        # ì¼ë°˜ì ìœ¼ë¡œ ë¬¼ë¦¬ ì½”ì–´ = ë…¼ë¦¬ ì½”ì–´ / 2 (í•˜ì´í¼ìŠ¤ë ˆë”©ì´ ìˆëŠ” ê²½ìš°)
        try:
            import psutil
            physical_cores = psutil.cpu_count(logical=False) or logical_cores
        except (ImportError, AttributeError):
            # psutil ì—†ê±°ë‚˜ ì •ë³´ ì—†ìœ¼ë©´ ë…¼ë¦¬ ì½”ì–´ì˜ 50-75%ë¡œ ì¶”ì •
            physical_cores = max(1, int(logical_cores * 0.625))

        # 3. ë¹„ë””ì˜¤ ê¸¸ì´ ê¸°ë°˜ ì¡°ì •
        # ì§§ì€ ë¹„ë””ì˜¤ëŠ” ì˜¤ë²„í—¤ë“œê°€ ë” í¬ë¯€ë¡œ ì›Œì»¤ ìˆ˜ ê°ì†Œ
        if video_duration_minutes < 5:
            # 5ë¶„ ë¯¸ë§Œ: ì‹±ê¸€ í”„ë¡œì„¸ìŠ¤ê°€ ë” íš¨ìœ¨ì 
            return 1
        elif video_duration_minutes < 15:
            # 5-15ë¶„: ë¬¼ë¦¬ ì½”ì–´ì˜ 50%
            max_workers = max(1, int(physical_cores * 0.5))
        elif video_duration_minutes < 30:
            # 15-30ë¶„: ë¬¼ë¦¬ ì½”ì–´ì˜ 75%
            max_workers = max(2, int(physical_cores * 0.75))
        else:
            # 30ë¶„ ì´ìƒ: ë¬¼ë¦¬ ì½”ì–´ ìˆ˜ (ë‹¨, ìµœëŒ€ 6ê°œë¡œ ì œí•œ)
            max_workers = min(physical_cores, 6)

        # 4. ë©”ëª¨ë¦¬ ê¸°ë°˜ ì¡°ì • (ì„ íƒì )
        try:
            import psutil
            available_gb = psutil.virtual_memory().available / (1024 ** 3)
            # ì›Œì»¤ë‹¹ ìµœì†Œ 2GB í•„ìš” (ì•ˆì „ ë§ˆì§„)
            memory_based_limit = max(1, int(available_gb / 2))
            max_workers = min(max_workers, memory_based_limit)
        except ImportError:
            pass

        # 5. ìµœì¢… ì œí•œ: ìµœì†Œ 1, ìµœëŒ€ 8
        optimal_workers = max(1, min(max_workers, 8))

        return optimal_workers

    def calculate_ssim(self, img1: np.ndarray, img2: np.ndarray) -> float:
        """
        ë‘ ì´ë¯¸ì§€ ê°„ SSIM ê³„ì‚°

        ì„±ëŠ¥ ìµœì í™”: config.ssim_scale < 1.0ì´ë©´ í•´ìƒë„ ì¶•ì†Œ í›„ ê³„ì‚°
        (segment êµ¬ê°„ ê²°ì •ì—ë§Œ ì‚¬ìš©, ì¶œë ¥ì€ ì›ë³¸ í•´ìƒë„ ìœ ì§€)
        """
        # í•´ìƒë„ ì¶•ì†Œ (ì„¤ì •ëœ ê²½ìš°)
        if self.config.ssim_scale < 1.0:
            h, w = img1.shape[:2]
            new_h = int(h * self.config.ssim_scale)
            new_w = int(w * self.config.ssim_scale)
            img1 = cv2.resize(img1, (new_w, new_h), interpolation=cv2.INTER_AREA)
            img2 = cv2.resize(img2, (new_w, new_h), interpolation=cv2.INTER_AREA)

        gray1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)
        gray2 = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)
        score, _ = ssim(gray1, gray2, full=True)
        return score

    def detect_segments(
        self,
        video_path: Path,
        progress_callback=None
    ) -> List[VideoSegment]:
        """
        ë¹„ë””ì˜¤ì—ì„œ ë°°ê²½ì´ ë™ì ì¸ ì„¸ê·¸ë¨¼íŠ¸ íƒì§€ (UIëŠ” ê³ ì •, ë°°ê²½ë§Œ ë³€í•¨)

        Args:
            video_path: ì…ë ¥ ë¹„ë””ì˜¤ ê²½ë¡œ
            progress_callback: ì§„í–‰ ìƒí™© ì½œë°± í•¨ìˆ˜(current, total)

        Returns:
            VideoSegment ë¦¬ìŠ¤íŠ¸
        """
        # ë©€í‹°í”„ë¡œì„¸ì‹± ì‚¬ìš© ì—¬ë¶€ í™•ì¸
        if self.config.use_multiprocessing:
            return self._detect_segments_mp(video_path, progress_callback)
        else:
            return self._detect_segments_single(video_path, progress_callback)

    def _detect_segments_single(
        self,
        video_path: Path,
        progress_callback=None
    ) -> List[VideoSegment]:
        """
        ì‹±ê¸€ í”„ë¡œì„¸ìŠ¤ ì„¸ê·¸ë¨¼íŠ¸ íƒì§€

        Args:
            video_path: ì…ë ¥ ë¹„ë””ì˜¤ ê²½ë¡œ
            progress_callback: ì§„í–‰ ìƒí™© ì½œë°± í•¨ìˆ˜(current, total)

        Returns:
            VideoSegment ë¦¬ìŠ¤íŠ¸
        """
        # ë¹„ë””ì˜¤ ë¦¬ë” (OpenCV ë˜ëŠ” PyAV)
        cap = None
        using_pyav = False

        # 1ë‹¨ê³„: OpenCVë¡œ ì—´ê¸° ì‹œë„
        cap = cv2.VideoCapture(str(video_path))
        if not cap.isOpened():
            raise RuntimeError(f"ë¹„ë””ì˜¤ë¥¼ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {video_path}")

        fps = cap.get(cv2.CAP_PROP_FPS)
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        self.stats['total_frames'] = total_frames

        print(f"ğŸ“¹ ë¹„ë””ì˜¤ ë¶„ì„ ì¤‘...")
        print(f"   - FPS: {fps:.2f}")
        print(f"   - ì´ í”„ë ˆì„: {total_frames:,}ê°œ")
        print(f"   - ê¸¸ì´: {total_frames / fps / 60:.1f}ë¶„")
        if self.config.ssim_scale < 1.0:
            print(f"   - SSIM í•´ìƒë„ ìŠ¤ì¼€ì¼: {self.config.ssim_scale:.2f} (ì„±ëŠ¥ ìµœì í™” ì ìš©, ì¶œë ¥ì€ ì›ë³¸ ìœ ì§€)")
        if self.config.frame_skip > 1:
            print(f"   - í”„ë ˆì„ ìŠ¤í‚µ: {self.config.frame_skip} (ë¹ ë¥¸ ëª¨ë“œ, ~{self.config.frame_skip}ë°° ì†ë„ í–¥ìƒ)")

        segments = []
        current_segment_start = 0
        dynamic_frame_count = 0
        ssim_buffer = []

        # ì²« í”„ë ˆì„ ì½ê¸° ì‹œë„
        ret, prev_frame = cap.read()
        if not ret:
            # 2ë‹¨ê³„: OpenCV ì‹¤íŒ¨ ì‹œ PyAVë¡œ ì „í™˜
            print("âš ï¸ OpenCVë¡œ ì²« í”„ë ˆì„ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            print("   ë¹„ë””ì˜¤ ì½”ë±ì´ OpenCVì™€ í˜¸í™˜ë˜ì§€ ì•Šì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            print("ğŸ”„ PyAVë¡œ ì „í™˜ì„ ì‹œë„í•©ë‹ˆë‹¤...")
            cap.release()

            # PyAVë¡œ ì—´ê¸°
            cap = PyAVVideoReader(video_path)
            if not cap.open():
                raise RuntimeError(
                    "ì²« í”„ë ˆì„ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n"
                    "ë¹„ë””ì˜¤ íŒŒì¼ì´ ì†ìƒë˜ì—ˆê±°ë‚˜ PyAVê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\n"
                    "PyAV ì„¤ì¹˜: pip install av"
                )

            # PyAVì—ì„œ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
            fps = cap.fps
            total_frames = cap.total_frames
            self.stats['total_frames'] = total_frames
            using_pyav = True

            # ì²« í”„ë ˆì„ ë‹¤ì‹œ ì½ê¸°
            ret, prev_frame = cap.read()
            if not ret:
                cap.release()
                raise RuntimeError("PyAVë¡œë„ ì²« í”„ë ˆì„ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")

        frame_idx = 0

        while True:
            # í”„ë ˆì„ ìŠ¤í‚µ ì ìš©
            for _ in range(self.config.frame_skip - 1):
                ret = cap.grab()  # í”„ë ˆì„ ì½ì§€ ì•Šê³  ê±´ë„ˆë›°ê¸°
                if not ret:
                    break
                frame_idx += 1

            ret, current_frame = cap.read()
            if not ret:
                break

            frame_idx += 1

            if progress_callback and frame_idx % 100 == 0:
                progress_callback(frame_idx, total_frames)

            # SSIM ê³„ì‚°
            ssim_score = self.calculate_ssim(prev_frame, current_frame)
            ssim_buffer.append(ssim_score)

            # ì¥ë©´ ì „í™˜ ê°ì§€
            if ssim_score < self.config.scene_change_threshold:
                self.stats['scene_changes'] += 1

                # ì´ì „ ì„¸ê·¸ë¨¼íŠ¸ ì €ì¥ (ì¡°ê±´ ì¶©ì¡± ì‹œ)
                if dynamic_frame_count >= self.config.min_dynamic_frames:
                    segment = self._create_segment(
                        current_segment_start,
                        frame_idx - 1,
                        fps,
                        ssim_buffer[:-1]
                    )

                    if self._is_valid_segment(segment):
                        segments.append(segment)
                        self.stats['dynamic_segments'] += 1
                    else:
                        if segment.duration < self.config.min_duration:
                            self.stats['discarded_short'] += 1
                        elif segment.avg_ssim > self.config.dynamic_high_threshold:
                            self.stats['discarded_static'] += 1
                        else:
                            self.stats['discarded_chaotic'] += 1

                # ìƒˆ ì„¸ê·¸ë¨¼íŠ¸ ì‹œì‘
                current_segment_start = frame_idx
                dynamic_frame_count = 0
                ssim_buffer = []

            # ë™ì  êµ¬ê°„ ì¹´ìš´íŠ¸ (SSIMì´ ì ì ˆí•œ ë²”ìœ„ ë‚´)
            elif (self.config.dynamic_low_threshold <= ssim_score <=
                  self.config.dynamic_high_threshold):
                dynamic_frame_count += 1

            # ìµœëŒ€ ê¸¸ì´ ì´ˆê³¼ ì‹œ ì„¸ê·¸ë¨¼íŠ¸ ë¶„í• 
            segment_frames = frame_idx - current_segment_start
            segment_duration = segment_frames / fps

            if segment_duration >= self.config.max_duration:
                if dynamic_frame_count >= self.config.min_dynamic_frames:
                    segment = self._create_segment(
                        current_segment_start,
                        frame_idx,
                        fps,
                        ssim_buffer
                    )

                    if self._is_valid_segment(segment):
                        segments.append(segment)
                        self.stats['dynamic_segments'] += 1

                current_segment_start = frame_idx
                dynamic_frame_count = 0
                ssim_buffer = []

            # ìµœëŒ€ ì„¸ê·¸ë¨¼íŠ¸ ìˆ˜ ë„ë‹¬
            if (self.config.max_segments and
                len(segments) >= self.config.max_segments):
                print(f"\nâš ï¸ ìµœëŒ€ ì„¸ê·¸ë¨¼íŠ¸ ìˆ˜({self.config.max_segments})ì— ë„ë‹¬í–ˆìŠµë‹ˆë‹¤.")
                break

            prev_frame = current_frame

        # ë§ˆì§€ë§‰ ì„¸ê·¸ë¨¼íŠ¸ ì²˜ë¦¬
        if dynamic_frame_count >= self.config.min_dynamic_frames:
            segment = self._create_segment(
                current_segment_start,
                frame_idx,
                fps,
                ssim_buffer
            )

            if self._is_valid_segment(segment):
                segments.append(segment)
                self.stats['dynamic_segments'] += 1

        cap.release()

        print(f"\nâœ… ì„¸ê·¸ë¨¼íŠ¸ íƒì§€ ì™„ë£Œ!")
        self._print_stats()

        return segments

    def _detect_segments_mp(
        self,
        video_path: Path,
        progress_callback=None
    ) -> List[VideoSegment]:
        """
        ë©€í‹°í”„ë¡œì„¸ì‹±ì„ ì‚¬ìš©í•œ ì„¸ê·¸ë¨¼íŠ¸ íƒì§€

        Args:
            video_path: ì…ë ¥ ë¹„ë””ì˜¤ ê²½ë¡œ
            progress_callback: ì§„í–‰ ìƒí™© ì½œë°± í•¨ìˆ˜(current, total)

        Returns:
            VideoSegment ë¦¬ìŠ¤íŠ¸
        """
        import multiprocessing as mp
        from functools import partial

        cap = cv2.VideoCapture(str(video_path))
        if not cap.isOpened():
            raise RuntimeError(f"ë¹„ë””ì˜¤ë¥¼ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {video_path}")

        fps = cap.get(cv2.CAP_PROP_FPS)
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        self.stats['total_frames'] = total_frames
        cap.release()

        video_duration_minutes = total_frames / fps / 60
        print(f"ğŸ“¹ ë¹„ë””ì˜¤ ë¶„ì„ ì¤‘ (ë©€í‹°í”„ë¡œì„¸ì‹±)...")
        print(f"   - FPS: {fps:.2f}")
        print(f"   - ì´ í”„ë ˆì„: {total_frames:,}ê°œ")
        print(f"   - ê¸¸ì´: {video_duration_minutes:.1f}ë¶„")
        if self.config.ssim_scale < 1.0:
            print(f"   - SSIM í•´ìƒë„ ìŠ¤ì¼€ì¼: {self.config.ssim_scale:.2f} (ì„±ëŠ¥ ìµœì í™” ì ìš©, ì¶œë ¥ì€ ì›ë³¸ ìœ ì§€)")
        if self.config.frame_skip > 1:
            print(f"   - í”„ë ˆì„ ìŠ¤í‚µ: {self.config.frame_skip} (ë¹ ë¥¸ ëª¨ë“œ, ~{self.config.frame_skip}ë°° ì†ë„ í–¥ìƒ)")

        # ì›Œì»¤ ìˆ˜ ê²°ì • (ì ì‘í˜•)
        if self.config.num_workers:
            # ì‚¬ìš©ìê°€ ëª…ì‹œì ìœ¼ë¡œ ì§€ì •í•œ ê²½ìš°
            num_workers = self.config.num_workers
            print(f"   - ì›Œì»¤ ìˆ˜: {num_workers}ê°œ (ì‚¬ìš©ì ì§€ì •)")
        else:
            # ìë™ ê³„ì‚°
            num_workers = self._calculate_optimal_workers(video_duration_minutes)
            cpu_count = mp.cpu_count()
            print(f"   - ì›Œì»¤ ìˆ˜: {num_workers}ê°œ / {cpu_count}ê°œ ë…¼ë¦¬ ì½”ì–´ (ìë™ ìµœì í™”)")

            # ì‹±ê¸€ í”„ë¡œì„¸ìŠ¤ë¡œ ì „í™˜ ê¶Œì¥
            if num_workers == 1:
                print(f"   â„¹ï¸ ë¹„ë””ì˜¤ê°€ ì§§ì•„ ì‹±ê¸€ í”„ë¡œì„¸ìŠ¤ ëª¨ë“œë¡œ ìë™ ì „í™˜í•©ë‹ˆë‹¤ (ì˜¤ë²„í—¤ë“œ ìµœì†Œí™”)")
                return self._detect_segments_single(video_path, progress_callback)

        # ì²­í¬ ë‹¨ìœ„ë¡œ ë¶„í•  (ë¹„ë””ì˜¤ ê¸¸ì´ì— ë”°ë¼ ë™ì  ì¡°ì •)
        # ì›Œì»¤ë‹¹ ìµœì†Œ 2ë¶„ ì‘ì—…ì„ ë³´ì¥í•˜ì—¬ ì˜¤ë²„í—¤ë“œ ìµœì†Œí™”
        min_chunk_duration = max(60.0, video_duration_minutes * 60 / num_workers / 2)
        chunk_duration = min(min_chunk_duration, 120.0)  # ìµœëŒ€ 2ë¶„
        overlap_duration = 5.0  # ì´ˆ
        chunk_frames = int(chunk_duration * fps)
        overlap_frames = int(overlap_duration * fps)

        chunks = []
        start_frame = 0
        while start_frame < total_frames:
            end_frame = min(start_frame + chunk_frames, total_frames)
            chunks.append((start_frame, end_frame))
            start_frame = end_frame - overlap_frames
            if start_frame >= total_frames - overlap_frames:
                break

        print(f"   - ì²­í¬ ìˆ˜: {len(chunks)}ê°œ (ì²­í¬ë‹¹ {chunk_duration/60:.1f}ë¶„, ì˜¤ë²„ë© {overlap_duration}ì´ˆ)")

        # ì²­í¬ ìˆ˜ê°€ ì›Œì»¤ ìˆ˜ë³´ë‹¤ ì ìœ¼ë©´ ì›Œì»¤ ìˆ˜ ì¡°ì •
        if len(chunks) < num_workers:
            num_workers = max(1, len(chunks))
            print(f"   â„¹ï¸ ì²­í¬ ìˆ˜ì— ë§ì¶° ì›Œì»¤ ìˆ˜ë¥¼ {num_workers}ê°œë¡œ ì¡°ì •")

        # ë³‘ë ¬ ì²˜ë¦¬
        worker_func = partial(
            _process_chunk_worker,
            video_path=str(video_path),
            config=self.config,
            fps=fps
        )

        with mp.Pool(num_workers) as pool:
            chunk_results = pool.map(worker_func, chunks)

        # ê²°ê³¼ ë³‘í•© (ì˜¤ë²„ë© êµ¬ê°„ ì¤‘ë³µ ì œê±°)
        all_segments = []
        for chunk_segments in chunk_results:
            all_segments.extend(chunk_segments)

        # ì¤‘ë³µ ì œê±° ë° ì •ë ¬
        segments = self._merge_overlapping_segments(all_segments)

        # í†µê³„ ì—…ë°ì´íŠ¸
        self.stats['dynamic_segments'] = len(segments)

        print(f"\nâœ… ì„¸ê·¸ë¨¼íŠ¸ íƒì§€ ì™„ë£Œ!")
        print(f"ğŸ“Š ì„¸ê·¸ë©˜í…Œì´ì…˜ í†µê³„:")
        print(f"   - ì´ í”„ë ˆì„: {self.stats['total_frames']:,}ê°œ")
        print(f"   - ë™ì  ì„¸ê·¸ë¨¼íŠ¸: {len(segments):,}ê°œ")

        return segments

    def _merge_overlapping_segments(self, segments: List[VideoSegment]) -> List[VideoSegment]:
        """
        ì˜¤ë²„ë©ë˜ëŠ” ì„¸ê·¸ë¨¼íŠ¸ ë³‘í•©

        Args:
            segments: ì„¸ê·¸ë¨¼íŠ¸ ë¦¬ìŠ¤íŠ¸

        Returns:
            ë³‘í•©ëœ ì„¸ê·¸ë¨¼íŠ¸ ë¦¬ìŠ¤íŠ¸
        """
        if not segments:
            return []

        # ì‹œì‘ ì‹œê°„ìˆœìœ¼ë¡œ ì •ë ¬
        sorted_segments = sorted(segments, key=lambda s: s.start_time)

        merged = [sorted_segments[0]]

        for current in sorted_segments[1:]:
            last = merged[-1]

            # ì˜¤ë²„ë©ë˜ëŠ” ê²½ìš° ë³‘í•©
            if current.start_time <= last.end_time:
                # ë” ê¸´ ì„¸ê·¸ë¨¼íŠ¸ ì„ íƒ
                if current.end_time > last.end_time:
                    merged[-1] = VideoSegment(
                        start_frame=last.start_frame,
                        end_frame=current.end_frame,
                        start_time=last.start_time,
                        end_time=current.end_time,
                        duration=current.end_time - last.start_time,
                        avg_ssim=(last.avg_ssim + current.avg_ssim) / 2
                    )
            else:
                merged.append(current)

        return merged

    def _create_segment(
        self,
        start_frame: int,
        end_frame: int,
        fps: float,
        ssim_scores: List[float]
    ) -> VideoSegment:
        """ì„¸ê·¸ë¨¼íŠ¸ ê°ì²´ ìƒì„±"""
        start_time = start_frame / fps
        end_time = end_frame / fps
        duration = end_time - start_time
        avg_ssim = np.mean(ssim_scores) if ssim_scores else 0.0

        return VideoSegment(
            start_frame=start_frame,
            end_frame=end_frame,
            start_time=start_time,
            end_time=end_time,
            duration=duration,
            avg_ssim=avg_ssim
        )

    def _is_valid_segment(self, segment: VideoSegment) -> bool:
        """ì„¸ê·¸ë¨¼íŠ¸ ìœ íš¨ì„± ê²€ì¦"""
        # ìµœì†Œ ê¸¸ì´ ì²´í¬
        if segment.duration < self.config.min_duration:
            return False

        # ë™ì  ë²”ìœ„ ì²´í¬ (í‰ê·  SSIMì´ ì ì ˆí•œ ë²”ìœ„ ë‚´)
        if not (self.config.dynamic_low_threshold <= segment.avg_ssim <=
                self.config.dynamic_high_threshold):
            return False

        return True

    def export_segments(
        self,
        video_path: Path,
        segments: List[VideoSegment],
        output_dir: Path,
        progress_callback=None
    ) -> List[Path]:
        """
        ì„¸ê·¸ë¨¼íŠ¸ë¥¼ ê°œë³„ ë¹„ë””ì˜¤ íŒŒì¼ë¡œ ì €ì¥ (ffmpeg ì‚¬ìš©)

        Args:
            video_path: ì›ë³¸ ë¹„ë””ì˜¤ ê²½ë¡œ
            segments: ì„¸ê·¸ë¨¼íŠ¸ ë¦¬ìŠ¤íŠ¸
            output_dir: ì¶œë ¥ ë””ë ‰í† ë¦¬
            progress_callback: ì§„í–‰ ìƒí™© ì½œë°±

        Returns:
            ì €ì¥ëœ ë¹„ë””ì˜¤ íŒŒì¼ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸
        """
        # ffmpeg í™•ì¸ ë° ìë™ ì„¤ì¹˜
        if not check_and_install_ffmpeg():
            raise RuntimeError(
                "ffmpegë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. "
                "í„°ë¯¸ë„ì„ ì¬ì‹œì‘í•˜ê±°ë‚˜ ìˆ˜ë™ìœ¼ë¡œ ì„¤ì¹˜í•´ì£¼ì„¸ìš”."
            )

        output_dir.mkdir(parents=True, exist_ok=True)

        saved_paths = []

        print(f"\nğŸ¬ ì„¸ê·¸ë¨¼íŠ¸ ë¹„ë””ì˜¤ ìƒì„± ì¤‘ (ffmpeg)...")

        for idx, segment in enumerate(segments):
            output_path = output_dir / f"segment_{idx+1:03d}.mp4"

            # ffmpegë¡œ ë¹„ë””ì˜¤ ìë¥´ê¸° (ì¬ì¸ì½”ë”© ì—†ì´ ë¹ ë¥´ê²Œ)
            cmd = [
                'ffmpeg',
                '-i', str(video_path),
                '-ss', str(segment.start_time),
                '-to', str(segment.end_time),
                '-c', 'copy',
                '-y',  # ë®ì–´ì“°ê¸°
                str(output_path)
            ]

            try:
                subprocess.run(cmd, check=True, capture_output=True, text=True)
                saved_paths.append(output_path)

                if progress_callback:
                    progress_callback(idx + 1, len(segments))

                print(f"   âœ“ segment_{idx+1:03d}.mp4 ({segment.duration:.1f}ì´ˆ, "
                      f"SSIM: {segment.avg_ssim:.3f})")
            except subprocess.CalledProcessError as e:
                print(f"   âš ï¸ segment_{idx+1:03d}.mp4 ìƒì„± ì‹¤íŒ¨: {e.stderr}")

        # ì±„íƒë˜ì§€ ì•Šì€ êµ¬ê°„ ì €ì¥ (ì‹¤í—˜ ê¸°ëŠ¥)
        if self.config.save_discarded:
            self._export_discarded_segments(video_path, segments, output_dir)

        print(f"\nâœ… {len(saved_paths)}ê°œ ì„¸ê·¸ë¨¼íŠ¸ ì €ì¥ ì™„ë£Œ!")
        return saved_paths

    def _export_discarded_segments(
        self,
        video_path: Path,
        accepted_segments: List[VideoSegment],
        output_dir: Path
    ):
        """
        ì±„íƒë˜ì§€ ì•Šì€ êµ¬ê°„ì„ else í´ë”ì— ì €ì¥

        Args:
            video_path: ì›ë³¸ ë¹„ë””ì˜¤ ê²½ë¡œ
            accepted_segments: ì±„íƒëœ ì„¸ê·¸ë¨¼íŠ¸ ë¦¬ìŠ¤íŠ¸
            output_dir: ì¶œë ¥ ë””ë ‰í† ë¦¬
        """
        # ffmpeg í™•ì¸ (ì´ë¯¸ export_segmentsì—ì„œ ì²´í¬í–ˆìœ¼ë¯€ë¡œ ì¬í™•ì¸ë§Œ)
        if not check_and_install_ffmpeg():
            print("âš ï¸ ffmpegë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ì–´ ì±„íƒë˜ì§€ ì•Šì€ êµ¬ê°„ ì €ì¥ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
            return

        # else í´ë” ìƒì„±
        else_dir = output_dir / "else"
        else_dir.mkdir(exist_ok=True)

        # ë¹„ë””ì˜¤ ì´ ê¸¸ì´ ê°€ì ¸ì˜¤ê¸°
        cap = cv2.VideoCapture(str(video_path))
        fps = cap.get(cv2.CAP_PROP_FPS)
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        total_duration = total_frames / fps
        cap.release()

        print(f"\nğŸ“¦ ì±„íƒë˜ì§€ ì•Šì€ êµ¬ê°„ ì €ì¥ ì¤‘...")

        # ì±„íƒëœ êµ¬ê°„ì„ ì‹œê°„ ìˆœìœ¼ë¡œ ì •ë ¬
        sorted_segments = sorted(accepted_segments, key=lambda s: s.start_time)

        # ë¹ˆ êµ¬ê°„ ì°¾ê¸°
        discarded_segments = []
        prev_end_time = 0.0

        for segment in sorted_segments:
            if segment.start_time > prev_end_time + 0.1:  # 0.1ì´ˆ ì´ìƒ ê³µë°±
                discarded_segments.append((prev_end_time, segment.start_time))
            prev_end_time = segment.end_time

        # ë§ˆì§€ë§‰ êµ¬ê°„ ì´í›„
        if prev_end_time < total_duration - 0.1:
            discarded_segments.append((prev_end_time, total_duration))

        # ë¹ˆ êµ¬ê°„ ì €ì¥
        for idx, (start_time, end_time) in enumerate(discarded_segments):
            output_path = else_dir / f"discarded_{idx+1:03d}.mp4"
            duration = end_time - start_time

            cmd = [
                'ffmpeg',
                '-i', str(video_path),
                '-ss', str(start_time),
                '-to', str(end_time),
                '-c', 'copy',
                '-y',
                str(output_path)
            ]

            try:
                subprocess.run(cmd, check=True, capture_output=True, text=True)
                print(f"   âœ“ discarded_{idx+1:03d}.mp4 ({duration:.1f}ì´ˆ)")
            except subprocess.CalledProcessError as e:
                print(f"   âš ï¸ discarded_{idx+1:03d}.mp4 ìƒì„± ì‹¤íŒ¨: {e.stderr}")

        print(f"âœ… {len(discarded_segments)}ê°œ ì±„íƒë˜ì§€ ì•Šì€ êµ¬ê°„ ì €ì¥ ì™„ë£Œ!")

    def save_metadata(
        self,
        output_dir: Path,
        video_path: Path,
        segments: List[VideoSegment]
    ):
        """ë©”íƒ€ë°ì´í„° ì €ì¥"""
        metadata = {
            'source_video': str(video_path),
            'timestamp': datetime.now().isoformat(),
            'config': {
                'scene_change_threshold': self.config.scene_change_threshold,
                'dynamic_low_threshold': self.config.dynamic_low_threshold,
                'dynamic_high_threshold': self.config.dynamic_high_threshold,
                'min_duration': self.config.min_duration,
                'max_duration': self.config.max_duration,
                'ssim_scale': self.config.ssim_scale,
            },
            'stats': self.stats,
            'segments': [
                {
                    'index': i + 1,
                    'filename': f"segment_{i+1:03d}.mp4",
                    'start_frame': seg.start_frame,
                    'end_frame': seg.end_frame,
                    'start_time': seg.start_time,
                    'end_time': seg.end_time,
                    'duration': seg.duration,
                    'avg_ssim': seg.avg_ssim
                }
                for i, seg in enumerate(segments)
            ]
        }

        metadata_path = output_dir / "segments_metadata.json"
        with open(metadata_path, 'w', encoding='utf-8') as f:
            json.dump(metadata, f, ensure_ascii=False, indent=2)

        print(f"\nğŸ’¾ ë©”íƒ€ë°ì´í„° ì €ì¥: {metadata_path}")

    def _print_stats(self):
        """í†µê³„ ì¶œë ¥"""
        print(f"\nğŸ“Š ì„¸ê·¸ë©˜í…Œì´ì…˜ í†µê³„:")
        print(f"   - ì´ í”„ë ˆì„: {self.stats['total_frames']:,}ê°œ")
        print(f"   - ì¥ë©´ ì „í™˜: {self.stats['scene_changes']:,}ê°œ")
        print(f"   - ë™ì  ì„¸ê·¸ë¨¼íŠ¸: {self.stats['dynamic_segments']:,}ê°œ")
        print(f"   - ì œì™¸ (ì§§ìŒ): {self.stats['discarded_short']:,}ê°œ")
        print(f"   - ì œì™¸ (ì •ì ): {self.stats['discarded_static']:,}ê°œ")
        print(f"   - ì œì™¸ (í˜¼ë€): {self.stats['discarded_chaotic']:,}ê°œ")


def main():
    parser = argparse.ArgumentParser(
        description="SSIM ê¸°ë°˜ ìŠ¤ë§ˆíŠ¸ ë¹„ë””ì˜¤ ì„¸ê·¸ë©˜í…Œì´ì…˜"
    )
    parser.add_argument(
        '--input',
        type=Path,
        required=True,
        help="ì…ë ¥ ë¹„ë””ì˜¤ ê²½ë¡œ"
    )
    parser.add_argument(
        '--output',
        type=Path,
        required=True,
        help="ì¶œë ¥ ë””ë ‰í† ë¦¬"
    )
    parser.add_argument(
        '--scene-threshold',
        type=float,
        default=0.3,
        help="ì¥ë©´ ì „í™˜ ì„ê³„ê°’ (ê¸°ë³¸: 0.3)"
    )
    parser.add_argument(
        '--dynamic-low',
        type=float,
        default=0.4,
        help="ë™ì  ë²”ìœ„ ìµœì†Œê°’ (ê¸°ë³¸: 0.4)"
    )
    parser.add_argument(
        '--dynamic-high',
        type=float,
        default=0.8,
        help="ë™ì  ë²”ìœ„ ìµœëŒ€ê°’ (ê¸°ë³¸: 0.8)"
    )
    parser.add_argument(
        '--min-duration',
        type=float,
        default=5.0,
        help="ìµœì†Œ ì„¸ê·¸ë¨¼íŠ¸ ê¸¸ì´ ì´ˆ (ê¸°ë³¸: 5.0)"
    )
    parser.add_argument(
        '--max-duration',
        type=float,
        default=60.0,
        help="ìµœëŒ€ ì„¸ê·¸ë¨¼íŠ¸ ê¸¸ì´ ì´ˆ (ê¸°ë³¸: 60.0)"
    )
    parser.add_argument(
        '--max-segments',
        type=int,
        default=None,
        help="ìµœëŒ€ ì„¸ê·¸ë¨¼íŠ¸ ìˆ˜ (ê¸°ë³¸: ë¬´ì œí•œ)"
    )
    parser.add_argument(
        '--ssim-scale',
        type=float,
        default=1.0,
        help="SSIM ê³„ì‚° ì‹œ í•´ìƒë„ ìŠ¤ì¼€ì¼ (0.25=4ë°° ë¹ ë¦„, 1.0=ì›ë³¸, ê¸°ë³¸: 1.0, ì¶œë ¥ì€ í•­ìƒ ì›ë³¸ í•´ìƒë„)"
    )
    parser.add_argument(
        '--frame-skip',
        type=int,
        default=1,
        help="í”„ë ˆì„ ìŠ¤í‚µ (1=ëª¨ë“  í”„ë ˆì„, 3=3í”„ë ˆì„ë§ˆë‹¤, ê¸°ë³¸: 1)"
    )
    parser.add_argument(
        '--save-discarded',
        action='store_true',
        help="ì±„íƒë˜ì§€ ì•Šì€ êµ¬ê°„ë„ else í´ë”ì— ì €ì¥ (ì‹¤í—˜ ê¸°ëŠ¥)"
    )
    parser.add_argument(
        '--no-multiprocessing',
        action='store_true',
        help="ë©€í‹°í”„ë¡œì„¸ì‹± ë¹„í™œì„±í™” (ê¸°ë³¸: í™œì„±í™”)"
    )
    parser.add_argument(
        '--workers',
        type=int,
        default=None,
        help="ì›Œì»¤ ìˆ˜ (ê¸°ë³¸: CPU ì½”ì–´ ìˆ˜)"
    )

    args = parser.parse_args()

    # ì„¤ì • ìƒì„±
    config = SegmentConfig(
        scene_change_threshold=args.scene_threshold,
        dynamic_low_threshold=args.dynamic_low,
        dynamic_high_threshold=args.dynamic_high,
        min_duration=args.min_duration,
        max_duration=args.max_duration,
        max_segments=args.max_segments,
        ssim_scale=args.ssim_scale,
        frame_skip=args.frame_skip,
        save_discarded=args.save_discarded,
        use_multiprocessing=not args.no_multiprocessing,
        num_workers=args.workers
    )

    # ì„¸ê·¸ë©˜í„° ìƒì„±
    segmenter = VideoSegmenter(config)

    # ì§„í–‰ ìƒí™© ì½œë°±
    def progress_callback(current, total):
        print(f"   ì§„í–‰: {current:,} / {total:,} ({current / total * 100:.1f}%)", end='\r')

    try:
        # ì„¸ê·¸ë¨¼íŠ¸ íƒì§€
        segments = segmenter.detect_segments(args.input, progress_callback)

        if not segments:
            print("\nâŒ ìœ íš¨í•œ ì„¸ê·¸ë¨¼íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return 1

        # ì„¸ê·¸ë¨¼íŠ¸ ë¹„ë””ì˜¤ ìƒì„±
        saved_paths = segmenter.export_segments(
            args.input,
            segments,
            args.output,
            progress_callback
        )

        # ë©”íƒ€ë°ì´í„° ì €ì¥
        segmenter.save_metadata(args.output, args.input, segments)

        print(f"\nâœ… ì™„ë£Œ!")
        print(f"   ì¶œë ¥ ë””ë ‰í† ë¦¬: {args.output}")
        print(f"   ì„¸ê·¸ë¨¼íŠ¸ ìˆ˜: {len(saved_paths)}ê°œ")

        total_duration = sum(seg.duration for seg in segments)
        print(f"   ì´ ê¸¸ì´: {total_duration / 60:.1f}ë¶„")

    except Exception as e:
        print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
        return 1

    return 0


if __name__ == '__main__':
    exit(main())
